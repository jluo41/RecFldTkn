{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "\n",
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "\n",
    "# WorkSpace\n",
    "KEY = 'WorkSpace'; WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY; print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "\n",
    "# Pipeline Space\n",
    "from proj_space import SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "# pprint(SPACE)\n",
    "\n",
    "# Available Packages\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_FN'], 'config_recfldtkn/')\n",
    "\n",
    "import datasets\n",
    "from recfldtkn.loadtools import load_ds_rec_and_info\n",
    "from recfldtkn.configfn import load_cohort_args, load_record_args\n",
    "from config_observer.CKPD import ckpd_to_CkpdObsConfig\n",
    "\n",
    "\n",
    "cohort_config = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "cohort_config['ckpd_to_CkpdObsConfig'] = ckpd_to_CkpdObsConfig\n",
    "cohort_config['ObsDTName'] = 'ObsDT'\n",
    "cohort_config['PID_ObsDT_columns'] = [cohort_config['RootID'], cohort_config['ObsDTName']]\n",
    "print(cohort_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DsCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. ************ RFT config ************\n",
    "RecName_to_dsRec, RecName_to_dsRecInfo = {}, {}\n",
    "cohort_label_list = [1]\n",
    "\n",
    "# 1. ************ Case Trigger config ************\n",
    "TriggerCaseMethod = 'TrulicityRx'\n",
    "\n",
    "\n",
    "# 2. ************ InputCaseSetName ************\n",
    "# option 1\n",
    "# InputCaseSetName = 'C1.2.3-CGM5MinEntry'\n",
    "# InputCaseSetName = 'sftcgmbf24haf2h-rs42-ds0.1-out0.1tstail0.1vd0.1'\n",
    "InputCaseSetName = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df354f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import fetch_trigger_tools\n",
    "\n",
    "Trigger_Tools = fetch_trigger_tools(TriggerCaseMethod, SPACE)\n",
    "case_id_columns = Trigger_Tools['case_id_columns']\n",
    "cohort_config['case_id_columns'] = case_id_columns\n",
    "case_id_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc714ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_case import get_ds_case_to_process\n",
    "\n",
    "\n",
    "InputCaseSetName, df_case = get_ds_case_to_process(InputCaseSetName, \n",
    "                                                   cohort_label_list, \n",
    "                                                   TriggerCaseMethod, \n",
    "                                                   cohort_config, \n",
    "                                                   SPACE, \n",
    "                                                   RecName_to_dsRec, \n",
    "                                                   RecName_to_dsRecInfo)\n",
    "\n",
    "logger.info(f'InputCaseSetName: {InputCaseSetName}')\n",
    "logger.info(f'df_case shape: {df_case.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ccd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = df_case.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_case import process_df_tagging_tasks_in_chunks\n",
    "from config_observer.QCF import cf_to_QueryCaseFeatConfig\n",
    "\n",
    "\n",
    "CASE_TAGGING_PROC_CONFIG = {\n",
    "    'use_CF_from_disk': False,\n",
    "    'use_CO_from_disk': False,\n",
    "    'start_chunk_id': 0,\n",
    "    'end_chunk_id': None,\n",
    "    'chunk_size': 500000,\n",
    "    'save_to_pickle': False,\n",
    "    'num_processors': 1\n",
    "}\n",
    "\n",
    "######################################\n",
    "TagMethod_List = ['PttBasicDF', 'EgmBf1Y']\n",
    "######################################\n",
    "\n",
    "if len(TagMethod_List) > 0:\n",
    "    logger.info(f'df_case shape: {df_case.shape}')\n",
    "    OutputCaseSetName, df_case = process_df_tagging_tasks_in_chunks(df_case, cohort_label_list, case_id_columns, \n",
    "                                                                    InputCaseSetName, \n",
    "                                                                    TagMethod_List, cf_to_QueryCaseFeatConfig, \n",
    "                                                                    cohort_config, SPACE, \n",
    "                                                                    RecName_to_dsRec, RecName_to_dsRecInfo,\n",
    "                                                                    **CASE_TAGGING_PROC_CONFIG)\n",
    "    logger.info(f'df_case shape: {df_case.shape}')\n",
    "\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0735f",
   "metadata": {},
   "source": [
    "# 3. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ad9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FilterMethod_List = [\n",
    "    'fPttBasicDF', \n",
    "    'fTailObsDT',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_case import process_df_filtering_tasks\n",
    "\n",
    "logger.info(f'-------------- (4) FilterMethod_List: {FilterMethod_List} --------------')\n",
    "if len(FilterMethod_List) > 0:\n",
    "    # logger.info(f'---------- before filtering: {df_case.shape} --------------')\n",
    "    df_case = process_df_filtering_tasks(df_case, FilterMethod_List, SPACE)\n",
    "    # logger.info(f'---------- after filtering: {df_case.shape} --------------')\n",
    "    logger.info(f'df_case shape: {df_case.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2626b8",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case # df_case_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_case import generate_random_tags, assign_caseSplitTag_to_dsCase\n",
    "\n",
    "##############\n",
    "# RANDOM_SEED = 42\n",
    "# downsample_ratio = 1 # 0.1 # 1 (don't drop any case), 0.1 (drop 90% of cases of one patient).\n",
    "# out_ratio = 0 # 0.1 # hold-out patients\n",
    "# test_ratio = 0.2 # 'tail0.1' #  '2023.10.15'#  # '0.1'\n",
    "# valid_ratio = 0 #  0.1 \n",
    "##############\n",
    "\n",
    "SplitDict = {\n",
    "    'RootID': cohort_config['RootID'],\n",
    "    'ObsDT': 'ObsDT',\n",
    "    'RANDOM_SEED': 42,\n",
    "    'downsample_ratio': 0.1,\n",
    "    'out_ratio': 0.1,\n",
    "    'test_ratio': 'tail0.1',\n",
    "    'valid_ratio': 0.1\n",
    "}\n",
    "\n",
    "\n",
    "# SplitMethod = f'rs{RANDOM_SEED}-ds{downsample_ratio}-out{out_ratio}ts{test_ratio}vd{valid_ratio}' \n",
    "# print(SplitMethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = assign_caseSplitTag_to_dsCase(df_case,  **SplitDict)\n",
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37630a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\ntotal---> recnum {len(df_case)}')\n",
    "for i in ['In', 'Out', 'Train', 'Valid', 'Test']:\n",
    "    print(i, df_case[i].mean())\n",
    "\n",
    "print('Valid/(Train+Test):', df_case['Valid'].sum() / (df_case['Train'].sum() + df_case['Valid'].sum()))\n",
    "\n",
    "subtype_list = ['patient_gender', 'patient_age_bucket',\n",
    "                 # 'patient_zipcode_3'\n",
    "                 ]\n",
    "# subtype_list = ['sex', 'a1cV0']\n",
    "for subtype in subtype_list:\n",
    "    for subname, df_sub in df_case.groupby(subtype):\n",
    "        print(f'\\n{subname}---> recnum {len(df_sub)}')\n",
    "        for i in ['In', 'Out', 'Train', 'Valid', 'Test']:\n",
    "            print(i, df_sub[i].mean())\n",
    "        print('Valid/(Train+Test):', df_sub['Valid'].sum() / (df_sub['Train'].sum() + df_sub['Valid'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec26aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
