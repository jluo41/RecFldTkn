{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b19d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Shared drives\\CDHAI-WellDoc\\2024-WellDocTest-SPACE\\_WellDoc-AI-CGMGPT-WorkSpace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:19:31,532:(config.py@58 datasets)]: PyTorch version 2.1.2+cu121 available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import logging\n",
    "from pprint import pprint \n",
    "\n",
    "# WorkSpace\n",
    "KEY = 'WorkSpace'; WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY; print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "\n",
    "# Pipeline Space\n",
    "from proj_space import SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "\n",
    "from recfldtkn.configfn import load_cohort_args\n",
    "from config_observer.CF import cf_to_CaseFeatConfig\n",
    "from config_observer.QCF import cf_to_QueryCaseFeatConfig\n",
    "from config_observer.CKPD import ckpd_to_CkpdObsConfig\n",
    "from recfldtkn.pipeline_dataset import pipeline_to_generate_dfcase_and_dataset\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_FN'], 'config_recfldtkn/')\n",
    "cohort_args = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "cohort_args['ckpd_to_CkpdObsConfig'] = ckpd_to_CkpdObsConfig\n",
    "cohort_args['ObsDTName'] = 'ObsDT'\n",
    "cohort_args['PID_ObsDT_columns'] = [cohort_args['RootID'], cohort_args['ObsDTName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9a4bf",
   "metadata": {},
   "source": [
    "# CF Proc Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904d84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_TAGGING_PROC_CONFIG = {\n",
    "    'use_CF_from_disk': False,\n",
    "    'use_CO_from_disk': False,\n",
    "    'start_chunk_id': 0,\n",
    "    'end_chunk_id': None,\n",
    "    'chunk_size': 500000,\n",
    "    'save_to_pickle': False,\n",
    "    'num_processors': 1,\n",
    "}\n",
    "\n",
    "\n",
    "CASE_FIEDLING_PROC_CONFIG = {\n",
    "    'use_CF_from_disk': False,\n",
    "    'use_CO_from_disk': False,\n",
    "    'start_chunk_id': 0,\n",
    "    'end_chunk_id': None,\n",
    "    'chunk_size': 100000,\n",
    "    'num_processors': 1\n",
    "}\n",
    "\n",
    "\n",
    "SAVE_DF_CASE = False\n",
    "SAVE_DS_DATA = False\n",
    "LOAD_DF_CASE = False\n",
    "LOAD_DS_DATA = False\n",
    "SAVE_TRIGGER_DF = False # False\n",
    "RANDOM_SAMPLE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7ac94",
   "metadata": {},
   "source": [
    "# Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94a5057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>ObsDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000037</td>\n",
       "      <td>2021-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000037</td>\n",
       "      <td>2021-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000048</td>\n",
       "      <td>2021-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000048</td>\n",
       "      <td>2021-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000048</td>\n",
       "      <td>2021-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>3000039</td>\n",
       "      <td>2023-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>3000039</td>\n",
       "      <td>2023-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>3000039</td>\n",
       "      <td>2023-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>3000039</td>\n",
       "      <td>2023-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>3000039</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2706 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PID      ObsDT\n",
       "0     1000037 2021-01-07\n",
       "1     1000037 2021-01-08\n",
       "2     1000048 2021-01-11\n",
       "3     1000048 2021-01-13\n",
       "4     1000048 2021-01-14\n",
       "...       ...        ...\n",
       "2701  3000039 2023-08-06\n",
       "2702  3000039 2023-08-07\n",
       "2703  3000039 2023-08-08\n",
       "2704  3000039 2023-08-11\n",
       "2705  3000039 2023-08-14\n",
       "\n",
       "[2706 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "CaseSetName = 'CGM5MinEntry'\n",
    "TriggerCasePath = os.path.join(SPACE['DATA_CaseSet'], f'{CaseSetName}.p')\n",
    "df_case1 = pd.read_pickle(TriggerCasePath) # (1000)\n",
    "\n",
    "CaseSetName = 'FoodEntryEOD'\n",
    "TriggerCasePath = os.path.join(SPACE['DATA_CaseSet'], f'{CaseSetName}.p')\n",
    "df_case2 = pd.read_pickle(TriggerCasePath) # (1000)\n",
    "\n",
    "df_case = pd.merge(df_case1, df_case2, how='inner')\n",
    "# df_case = df_case1.sample(1000, random_state=0)\n",
    "# df_case = df_case1.sample(1000, random_state=0).reset_index(drop = True)\n",
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d4c211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_Data/4-Data_CaseSet\\TestCaseSet.p\n"
     ]
    }
   ],
   "source": [
    "TriggerCasePath = os.path.join(SPACE['DATA_CaseSet'], f'TestCaseSet.p')\n",
    "print(TriggerCasePath)\n",
    "df_case.to_pickle(TriggerCasePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfd7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config_name = 'CgmGptMedalData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e2a682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if ds_config_name == 'CgmGptMedalData':\n",
    "    # ################################################################\n",
    "    # 0. ************ RFT config ************\n",
    "    RecName_to_dsRec, RecName_to_dsRecInfo = {}, {}\n",
    "    cohort_label_list = [1, 2, 3]\n",
    "    # 1. ************ Case Trigger config ************\n",
    "    TriggerCaseMethod = 'CGM5MinEntry'\n",
    "    # 2. ************ InputCaseSetName ************\n",
    "    # InputCaseSetName = 'sftcgmbf24haf2h-rs42-ds0.1-out0.1tstail0.1vd0.1'\n",
    "    InputCaseSetName = 'TestCaseSet'\n",
    "    # 3. ************ CaseTagging: TagMethod_List ************\n",
    "    TagMethod_List = [\n",
    "                      'PttBasicWD', \n",
    "                      'Bf24hCGMinfo', 'Af2hCGMinfo',\n",
    "                    #   'Bf24hCGMrn', 'Af2hCGMrn',\n",
    "                    #   'Bf24hCGMmode', 'Af2hCGMmode', \n",
    "                      \n",
    "                      'Bf1mMEDALcf', 'Bf24hMEDALcf', \n",
    "                      'Bf2hMEDALcf', 'Af2hMEDALcf',\n",
    "                      ]\n",
    "    \n",
    "    # 4. ************ CaseFiltering: FilterMethod_List ************\n",
    "    FilterMethod_List = ['fPttBasicWD', \n",
    "                         'fBf24h280CGM',\n",
    "                         'fAf2h24CGM', \n",
    "                         'fBf24HModePctn40', \n",
    "                         'fAf2HModePctn40',\n",
    "                         ]\n",
    "    # 5. ************ CaseSpliting: SplitDict ************\n",
    "    SplitDict = {}\n",
    "    # 6. ************ CaseSet Selection ************\n",
    "    CaseSplitConfig = {}\n",
    "    # 7. ************ CaseFeat: Feature Enriching ************\n",
    "    CaseFeat_List =   [\n",
    "                      'TargetCGM.Bf24H', \n",
    "                      'TargetCGM.Af2H',\n",
    "                      \n",
    "                      'TimeSparse.Bf24H', \n",
    "                      'TimeSparse.Af2H',\n",
    "                      \n",
    "                      'MedSparse.Bf24H', \n",
    "                      'MedSparse.Af2H',\n",
    "                      \n",
    "                      'EduSparse.Bf24H', \n",
    "                      'EduSparse.Af2H',\n",
    "                      \n",
    "                      'DietSparse.Bf24H', \n",
    "                      'DietSparse.Af2H',\n",
    "                      \n",
    "                      'ActivitySparse.Bf24H', \n",
    "                      'ActivitySparse.Af2H',\n",
    "                      \n",
    "                      'LabVitalSparse.Bf24H', \n",
    "                      'LabVitalSparse.Af2H',\n",
    "                      ]\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Invalid ds_config_name: {ds_config_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136a3d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:19:48,249:(pipeline_dataset.py@74 recfldtkn.pipeline_dataset)]: -------------- (0) RecName_to_dsRec: [] --------------\n",
      "[INFO:2024-04-21 09:19:48,250:(pipeline_dataset.py@78 recfldtkn.pipeline_dataset)]: -------------- (1) TriggerCaseMethod: CGM5MinEntry --------------\n",
      "[INFO:2024-04-21 09:19:48,257:(pipeline_dataset.py@84 recfldtkn.pipeline_dataset)]: -------------- (2) InputCaseSetName: TestCaseSet --------------\n",
      "[INFO:2024-04-21 09:19:48,265:(pipeline_dataset.py@95 recfldtkn.pipeline_dataset)]: InputCaseSetName: TestCaseSet\n",
      "[INFO:2024-04-21 09:19:48,266:(pipeline_dataset.py@96 recfldtkn.pipeline_dataset)]: df_case shape: (2706, 2)\n",
      "[INFO:2024-04-21 09:19:48,266:(pipeline_dataset.py@130 recfldtkn.pipeline_dataset)]: ds_case path: ../_Data/4-Data_CaseSet\\TestCaseSet-PttBasicWD.Bf24hCGMinfo.Af2hCGMinfo.Bf1mMEDALcf.Bf24hMEDALcf.Bf2hMEDALcf.Af2hMEDALcf-fPttBasicWD.fBf24h280CGM.fAf2h24CGM.fBf24HModePctn40.fAf2HModePctn40.p\n",
      "[INFO:2024-04-21 09:19:48,267:(pipeline_dataset.py@137 recfldtkn.pipeline_dataset)]: -------------- execute processing df_case --------------\n",
      "[INFO:2024-04-21 09:19:48,268:(pipeline_dataset.py@145 recfldtkn.pipeline_dataset)]: randomly selected df_case shape: (100, 2)\n",
      "[INFO:2024-04-21 09:19:48,268:(pipeline_dataset.py@149 recfldtkn.pipeline_dataset)]: -------------- (1.a) TagMethod_List: ['PttBasicWD', 'Bf24hCGMinfo', 'Af2hCGMinfo', 'Bf1mMEDALcf', 'Bf24hMEDALcf', 'Bf2hMEDALcf', 'Af2hMEDALcf'] --------------\n",
      "[INFO:2024-04-21 09:19:48,268:(pipeline_case.py@420 recfldtkn.pipeline_case)]: chunk_id_list: range(0, 1)\n",
      "[INFO:2024-04-21 09:19:48,403:(pipeline_case.py@308 recfldtkn.pipeline_case)]: ds_info is P: Dataset({\n",
      "    features: ['PID', 'PatientID', 'YearOfBirth', 'ActivationDate', 'MRSegmentModifiedDateTime', 'UserTimeZone', 'UserTimeZoneOffset', 'Gender', 'MRSegmentID', 'DiseaseType'],\n",
      "    num_rows: 11621\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567ee5526ee14e3baf067de9f57c8b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2334eb2aaa14860a3bd666fae11e495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:03,071:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n",
      "[INFO:2024-04-21 09:20:03,313:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4a8583725c41c59b6e904aba9a4232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:07,173:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n",
      "[INFO:2024-04-21 09:20:07,348:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e0c375d1f74dab966d3e81b7fba725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:10,368:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n",
      "[INFO:2024-04-21 09:20:10,596:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b635c6ae008d4d18989762a26354426d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:13,212:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n",
      "[INFO:2024-04-21 09:20:13,362:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79356f38274a477cae5c0bff0433809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:15,572:(pipeline_case.py@462 recfldtkn.pipeline_case)]: chunk_id: 0, df_case_chunk_tagged: (100, 79)\n",
      "[INFO:2024-04-21 09:20:15,573:(pipeline_dataset.py@157 recfldtkn.pipeline_dataset)]: df_case shape: (100, 79)\n",
      "[INFO:2024-04-21 09:20:15,574:(pipeline_dataset.py@161 recfldtkn.pipeline_dataset)]: -------------- (1.b) FilterMethod_List: ['fPttBasicWD', 'fBf24h280CGM', 'fAf2h24CGM', 'fBf24HModePctn40', 'fAf2HModePctn40'] --------------\n",
      "[INFO:2024-04-21 09:20:15,574:(pipeline_case.py@958 recfldtkn.pipeline_case)]: FilterMethod: fPttBasicWD\n",
      "[INFO:2024-04-21 09:20:15,586:(pipeline_case.py@963 recfldtkn.pipeline_case)]: before filtering: (100, 79)\n",
      "[INFO:2024-04-21 09:20:15,587:(pipeline_case.py@965 recfldtkn.pipeline_case)]: after filtering: (100, 79)\n",
      "[INFO:2024-04-21 09:20:15,587:(pipeline_case.py@958 recfldtkn.pipeline_case)]: FilterMethod: fBf24h280CGM\n",
      "[INFO:2024-04-21 09:20:15,596:(pipeline_case.py@963 recfldtkn.pipeline_case)]: before filtering: (100, 79)\n",
      "[INFO:2024-04-21 09:20:15,597:(pipeline_case.py@965 recfldtkn.pipeline_case)]: after filtering: (80, 79)\n",
      "[INFO:2024-04-21 09:20:15,598:(pipeline_case.py@958 recfldtkn.pipeline_case)]: FilterMethod: fAf2h24CGM\n",
      "[INFO:2024-04-21 09:20:15,605:(pipeline_case.py@963 recfldtkn.pipeline_case)]: before filtering: (80, 79)\n",
      "[INFO:2024-04-21 09:20:15,606:(pipeline_case.py@965 recfldtkn.pipeline_case)]: after filtering: (78, 79)\n",
      "[INFO:2024-04-21 09:20:15,606:(pipeline_case.py@958 recfldtkn.pipeline_case)]: FilterMethod: fBf24HModePctn40\n",
      "[INFO:2024-04-21 09:20:15,613:(pipeline_case.py@963 recfldtkn.pipeline_case)]: before filtering: (78, 79)\n",
      "[INFO:2024-04-21 09:20:15,614:(pipeline_case.py@965 recfldtkn.pipeline_case)]: after filtering: (78, 79)\n",
      "[INFO:2024-04-21 09:20:15,614:(pipeline_case.py@958 recfldtkn.pipeline_case)]: FilterMethod: fAf2HModePctn40\n",
      "[INFO:2024-04-21 09:20:15,621:(pipeline_case.py@963 recfldtkn.pipeline_case)]: before filtering: (78, 79)\n",
      "[INFO:2024-04-21 09:20:15,622:(pipeline_case.py@965 recfldtkn.pipeline_case)]: after filtering: (75, 79)\n",
      "[INFO:2024-04-21 09:20:15,622:(pipeline_dataset.py@166 recfldtkn.pipeline_dataset)]: df_case shape: (75, 79)\n",
      "[INFO:2024-04-21 09:20:15,622:(pipeline_dataset.py@169 recfldtkn.pipeline_dataset)]: -------------- (1.c) SplitDict: {} --------------\n",
      "[INFO:2024-04-21 09:20:15,623:(pipeline_dataset.py@192 recfldtkn.pipeline_dataset)]: -------------- (2.a) Dataset Split: {} --------------\n",
      "[INFO:2024-04-21 09:20:15,625:(pipeline_dataset.py@199 recfldtkn.pipeline_dataset)]: ds_case_dict: \n",
      "DatasetDict({\n",
      "    inference: Dataset({\n",
      "        features: ['PID', 'ObsDT'],\n",
      "        num_rows: 75\n",
      "    })\n",
      "})\n",
      "[INFO:2024-04-21 09:20:15,626:(pipeline_dataset.py@202 recfldtkn.pipeline_dataset)]: -------------- (2.b) Dataset Case Fielding: ['TargetCGM.Bf24H', 'TargetCGM.Af2H', 'TimeSparse.Bf24H', 'TimeSparse.Af2H', 'MedSparse.Bf24H', 'MedSparse.Af2H', 'EduSparse.Bf24H', 'EduSparse.Af2H', 'DietSparse.Bf24H', 'DietSparse.Af2H', 'ActivitySparse.Bf24H', 'ActivitySparse.Af2H', 'LabVitalSparse.Bf24H', 'LabVitalSparse.Af2H'] --------------\n",
      "[INFO:2024-04-21 09:20:15,627:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [TargetCGM.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:20:15,627:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:20:15,627:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:20:15,630:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: TargetCGM.Bf24H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:20:15,665:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\CGM5Min.yaml\n",
      "[INFO:2024-04-21 09:20:21,995:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\CGM5Min.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedc0560b67a4594944c79152ca8014a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:29,303:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [TargetCGM.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:20:29,304:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat TargetCGM.Bf24H, \n",
      "[INFO:2024-04-21 09:20:29,304:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:20:29,304:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'TargetCGM.Bf24H.input_ids'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:20:29,306:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [TargetCGM.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:20:29,307:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:20:29,307:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:20:29,309:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: TargetCGM.Af2H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:20:29,318:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\CGM5Min.yaml\n",
      "[INFO:2024-04-21 09:20:35,782:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\CGM5Min.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3158f057764cf0bd5e73647dbb7cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:42,588:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [TargetCGM.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:20:42,589:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat TargetCGM.Af2H, \n",
      "[INFO:2024-04-21 09:20:42,590:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:20:42,590:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'TargetCGM.Af2H.input_ids'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:20:42,593:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [TimeSparse.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:20:42,593:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:20:42,594:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:20:42,596:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: TimeSparse.Bf24H, chunk_id: 0, s0-e75 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9873a792c35144878674774f1a896a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:20:56,047:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [TimeSparse.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:20:56,048:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat TimeSparse.Bf24H, \n",
      "[INFO:2024-04-21 09:20:56,048:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:20:56,049:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'TimeSparse.Bf24H.timeinfo', 'TimeSparse.Bf24H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:20:56,051:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [TimeSparse.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:20:56,051:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:20:56,052:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:20:56,054:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: TimeSparse.Af2H, chunk_id: 0, s0-e75 -------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7081745fc12b4cd3971a57658dc053ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:08,929:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [TimeSparse.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:08,930:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat TimeSparse.Af2H, \n",
      "[INFO:2024-04-21 09:21:08,931:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:08,931:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'TimeSparse.Af2H.timeinfo', 'TimeSparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:08,933:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [MedSparse.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:08,934:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:08,934:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:08,937:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: MedSparse.Bf24H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:08,970:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedPres.yaml\n",
      "[INFO:2024-04-21 09:21:09,170:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:09,578:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:09,786:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\ImpMed.yaml\n",
      "[INFO:2024-04-21 09:21:09,890:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n",
      "[INFO:2024-04-21 09:21:09,927:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedPres.yaml\n",
      "[INFO:2024-04-21 09:21:10,077:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:10,305:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:10,545:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\ImpMed.yaml\n",
      "[INFO:2024-04-21 09:21:10,643:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c433465d19cd47b2870c0d65b28ec8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:11,693:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [MedSparse.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:11,694:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat MedSparse.Bf24H, \n",
      "[INFO:2024-04-21 09:21:11,694:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:11,695:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'MedSparse.Bf24H.timestep', 'MedSparse.Bf24H.input_ids', 'MedSparse.Bf24H.input_wgts', 'MedSparse.Bf24H.timeinfo', 'MedSparse.Bf24H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:11,697:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [MedSparse.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:11,698:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:11,698:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:11,700:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: MedSparse.Af2H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:11,708:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedPres.yaml\n",
      "[INFO:2024-04-21 09:21:11,882:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:12,281:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:12,483:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\ImpMed.yaml\n",
      "[INFO:2024-04-21 09:21:12,586:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n",
      "[INFO:2024-04-21 09:21:12,621:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedPres.yaml\n",
      "[INFO:2024-04-21 09:21:12,764:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:12,986:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\MedAdmin.yaml\n",
      "[INFO:2024-04-21 09:21:13,209:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\ImpMed.yaml\n",
      "[INFO:2024-04-21 09:21:13,279:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\ImpMed_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333f8aa5ece646bba3df51cf896aa082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:13,904:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [MedSparse.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:13,904:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat MedSparse.Af2H, \n",
      "[INFO:2024-04-21 09:21:13,904:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:13,905:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'MedSparse.Af2H.timestep', 'MedSparse.Af2H.input_ids', 'MedSparse.Af2H.input_wgts', 'MedSparse.Af2H.timeinfo', 'MedSparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:13,908:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [EduSparse.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:13,908:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:13,908:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:13,911:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: EduSparse.Bf24H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:13,928:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Cmt.yaml\n",
      "[INFO:2024-04-21 09:21:14,172:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LessonProg.yaml\n",
      "[INFO:2024-04-21 09:21:14,184:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n",
      "[INFO:2024-04-21 09:21:14,314:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Cmt.yaml\n",
      "[INFO:2024-04-21 09:21:14,500:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LessonProg.yaml\n",
      "[INFO:2024-04-21 09:21:14,507:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017f8e64220f4c54a58b901b3360a5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:14,950:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [EduSparse.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:14,951:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat EduSparse.Bf24H, \n",
      "[INFO:2024-04-21 09:21:14,951:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:14,952:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'EduSparse.Bf24H.timestep', 'EduSparse.Bf24H.input_ids', 'EduSparse.Bf24H.input_wgts', 'EduSparse.Bf24H.timeinfo', 'EduSparse.Bf24H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:14,954:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [EduSparse.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:14,955:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:14,955:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:14,957:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: EduSparse.Af2H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:14,967:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Cmt.yaml\n",
      "[INFO:2024-04-21 09:21:15,159:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LessonProg.yaml\n",
      "[INFO:2024-04-21 09:21:15,186:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n",
      "[INFO:2024-04-21 09:21:15,305:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Cmt.yaml\n",
      "[INFO:2024-04-21 09:21:15,440:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LessonProg.yaml\n",
      "[INFO:2024-04-21 09:21:15,461:(loadtools.py@156 recfldtkn.loadtools)]: No such folder: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\LessonProg_data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7207b73a26471e92fed903ac39590a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:15,902:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [EduSparse.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:15,902:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat EduSparse.Af2H, \n",
      "[INFO:2024-04-21 09:21:15,903:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:15,903:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'EduSparse.Af2H.timestep', 'EduSparse.Af2H.input_ids', 'EduSparse.Af2H.input_wgts', 'EduSparse.Af2H.timeinfo', 'EduSparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:15,906:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [DietSparse.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:15,907:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:15,907:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:15,909:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: DietSparse.Bf24H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:15,920:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n",
      "[INFO:2024-04-21 09:21:16,137:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n",
      "[INFO:2024-04-21 09:21:16,360:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n",
      "[INFO:2024-04-21 09:21:16,582:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819610b10e6a45c8b11bf9fe1dc9db0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:17,697:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [DietSparse.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:17,698:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat DietSparse.Bf24H, \n",
      "[INFO:2024-04-21 09:21:17,698:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:17,698:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'DietSparse.Bf24H.timestep', 'DietSparse.Bf24H.input_ids', 'DietSparse.Bf24H.input_wgts', 'DietSparse.Bf24H.timeinfo', 'DietSparse.Bf24H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:17,702:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [DietSparse.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:17,702:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:17,703:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:17,705:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: DietSparse.Af2H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:17,712:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n",
      "[INFO:2024-04-21 09:21:17,925:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n",
      "[INFO:2024-04-21 09:21:18,142:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n",
      "[INFO:2024-04-21 09:21:18,371:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\FoodRec.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c0e88955a4488080dbe3914e145e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:18,990:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [DietSparse.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:18,991:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat DietSparse.Af2H, \n",
      "[INFO:2024-04-21 09:21:18,991:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:18,991:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'DietSparse.Af2H.timestep', 'DietSparse.Af2H.input_ids', 'DietSparse.Af2H.input_wgts', 'DietSparse.Af2H.timeinfo', 'DietSparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:18,994:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [ActivitySparse.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:18,994:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:18,995:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:18,997:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: ActivitySparse.Bf24H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:19,038:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n",
      "[INFO:2024-04-21 09:21:19,357:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n",
      "[INFO:2024-04-21 09:21:19,558:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n",
      "[INFO:2024-04-21 09:21:19,742:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de50ea868d7744c5bca17f77ceeb1d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:20,590:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [ActivitySparse.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:20,590:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat ActivitySparse.Bf24H, \n",
      "[INFO:2024-04-21 09:21:20,591:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:20,591:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'ActivitySparse.Bf24H.timestep', 'ActivitySparse.Bf24H.input_ids', 'ActivitySparse.Bf24H.input_wgts', 'ActivitySparse.Bf24H.timeinfo', 'ActivitySparse.Bf24H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:20,594:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [ActivitySparse.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:20,594:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:20,595:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:20,597:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: ActivitySparse.Af2H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:20,602:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n",
      "[INFO:2024-04-21 09:21:20,930:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n",
      "[INFO:2024-04-21 09:21:21,098:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n",
      "[INFO:2024-04-21 09:21:21,285:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\Exercise.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f4081706a64714be8a4d0ed4c5ab21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:21,870:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [ActivitySparse.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:21,871:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat ActivitySparse.Af2H, \n",
      "[INFO:2024-04-21 09:21:21,871:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:21,872:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'ActivitySparse.Af2H.timestep', 'ActivitySparse.Af2H.input_ids', 'ActivitySparse.Af2H.input_wgts', 'ActivitySparse.Af2H.timeinfo', 'ActivitySparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:21,875:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [LabVitalSparse.Bf24H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:21,875:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:21,876:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:21,878:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: LabVitalSparse.Bf24H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:21,891:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\WeightU.yaml\n",
      "[INFO:2024-04-21 09:21:22,199:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\BP.yaml\n",
      "[INFO:2024-04-21 09:21:22,492:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n",
      "[INFO:2024-04-21 09:21:22,754:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n",
      "[INFO:2024-04-21 09:21:22,936:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\WeightU.yaml\n",
      "[INFO:2024-04-21 09:21:23,077:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\BP.yaml\n",
      "[INFO:2024-04-21 09:21:23,251:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n",
      "[INFO:2024-04-21 09:21:23,391:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d536d9b88243738f5bd8444f95322b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:24,198:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [LabVitalSparse.Bf24H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:24,198:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat LabVitalSparse.Bf24H, \n",
      "[INFO:2024-04-21 09:21:24,198:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:24,199:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'LabVitalSparse.Bf24H.timestep', 'LabVitalSparse.Bf24H.input_ids', 'LabVitalSparse.Bf24H.input_wgts', 'LabVitalSparse.Bf24H.timeinfo', 'LabVitalSparse.Bf24H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:24,201:(pipeline_case.py@604 recfldtkn.pipeline_case)]: \n",
      "\n",
      "\n",
      "\n",
      "----------------------ds 75: START one CaseFeat [LabVitalSparse.Af2H] for splitname [inference]\n",
      "[INFO:2024-04-21 09:21:24,202:(pipeline_case.py@605 recfldtkn.pipeline_case)]: chunk_id_list [0]\n",
      "[INFO:2024-04-21 09:21:24,202:(pipeline_case.py@611 recfldtkn.pipeline_case)]: ds 75\n",
      "[INFO:2024-04-21 09:21:24,204:(pipeline_case.py@491 recfldtkn.pipeline_case)]: process: df_case: 75, splitname: inference, CaseFeat: LabVitalSparse.Af2H, chunk_id: 0, s0-e75 -------------\n",
      "[INFO:2024-04-21 09:21:24,216:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\WeightU.yaml\n",
      "[INFO:2024-04-21 09:21:24,474:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\BP.yaml\n",
      "[INFO:2024-04-21 09:21:24,671:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n",
      "[INFO:2024-04-21 09:21:24,826:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n",
      "[INFO:2024-04-21 09:21:24,987:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\WeightU.yaml\n",
      "[INFO:2024-04-21 09:21:25,146:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\BP.yaml\n",
      "[INFO:2024-04-21 09:21:25,302:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n",
      "[INFO:2024-04-21 09:21:25,428:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn/Record\\LabTest.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545b6f9c3d084da387c5fc1edb974324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-21 09:21:26,154:(pipeline_case.py@630 recfldtkn.pipeline_case)]: ds 75: finish one CaseFeat [LabVitalSparse.Af2H] for splitname [inference]\n",
      "\n",
      "\n",
      "\n",
      "[INFO:2024-04-21 09:21:26,155:(pipeline_case.py@631 recfldtkn.pipeline_case)]: \n",
      "\n",
      "++++++++ DONE ds: 75, splitname: inference, CaseFeat LabVitalSparse.Af2H, \n",
      "[INFO:2024-04-21 09:21:26,155:(pipeline_case.py@632 recfldtkn.pipeline_case)]: the number of results in ds_case_split_cf_result_list: 1\n",
      "[INFO:2024-04-21 09:21:26,155:(pipeline_case.py@639 recfldtkn.pipeline_case)]: Dataset({\n",
      "    features: ['PID', 'ObsDT', 'LabVitalSparse.Af2H.timestep', 'LabVitalSparse.Af2H.input_ids', 'LabVitalSparse.Af2H.input_wgts', 'LabVitalSparse.Af2H.timeinfo', 'LabVitalSparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})\n",
      "[INFO:2024-04-21 09:21:26,161:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf TargetCGM.Bf24H: ds_case_split_cf: ['TargetCGM.Bf24H.input_ids']\n",
      "[INFO:2024-04-21 09:21:26,164:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf TargetCGM.Af2H: ds_case_split_cf: ['TargetCGM.Af2H.input_ids']\n",
      "[INFO:2024-04-21 09:21:26,168:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf TimeSparse.Bf24H: ds_case_split_cf: ['TimeSparse.Bf24H.timeinfo', 'TimeSparse.Bf24H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,170:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf TimeSparse.Af2H: ds_case_split_cf: ['TimeSparse.Af2H.timeinfo', 'TimeSparse.Af2H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,173:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf MedSparse.Bf24H: ds_case_split_cf: ['MedSparse.Bf24H.timestep', 'MedSparse.Bf24H.input_ids', 'MedSparse.Bf24H.input_wgts', 'MedSparse.Bf24H.timeinfo', 'MedSparse.Bf24H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,176:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf MedSparse.Af2H: ds_case_split_cf: ['MedSparse.Af2H.timestep', 'MedSparse.Af2H.input_ids', 'MedSparse.Af2H.input_wgts', 'MedSparse.Af2H.timeinfo', 'MedSparse.Af2H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,179:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf EduSparse.Bf24H: ds_case_split_cf: ['EduSparse.Bf24H.timestep', 'EduSparse.Bf24H.input_ids', 'EduSparse.Bf24H.input_wgts', 'EduSparse.Bf24H.timeinfo', 'EduSparse.Bf24H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,182:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf EduSparse.Af2H: ds_case_split_cf: ['EduSparse.Af2H.timestep', 'EduSparse.Af2H.input_ids', 'EduSparse.Af2H.input_wgts', 'EduSparse.Af2H.timeinfo', 'EduSparse.Af2H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,185:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf DietSparse.Bf24H: ds_case_split_cf: ['DietSparse.Bf24H.timestep', 'DietSparse.Bf24H.input_ids', 'DietSparse.Bf24H.input_wgts', 'DietSparse.Bf24H.timeinfo', 'DietSparse.Bf24H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,188:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf DietSparse.Af2H: ds_case_split_cf: ['DietSparse.Af2H.timestep', 'DietSparse.Af2H.input_ids', 'DietSparse.Af2H.input_wgts', 'DietSparse.Af2H.timeinfo', 'DietSparse.Af2H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,191:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf ActivitySparse.Bf24H: ds_case_split_cf: ['ActivitySparse.Bf24H.timestep', 'ActivitySparse.Bf24H.input_ids', 'ActivitySparse.Bf24H.input_wgts', 'ActivitySparse.Bf24H.timeinfo', 'ActivitySparse.Bf24H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,194:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf ActivitySparse.Af2H: ds_case_split_cf: ['ActivitySparse.Af2H.timestep', 'ActivitySparse.Af2H.input_ids', 'ActivitySparse.Af2H.input_wgts', 'ActivitySparse.Af2H.timeinfo', 'ActivitySparse.Af2H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,196:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf LabVitalSparse.Bf24H: ds_case_split_cf: ['LabVitalSparse.Bf24H.timestep', 'LabVitalSparse.Bf24H.input_ids', 'LabVitalSparse.Bf24H.input_wgts', 'LabVitalSparse.Bf24H.timeinfo', 'LabVitalSparse.Bf24H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,199:(pipeline_case.py@663 recfldtkn.pipeline_case)]: cf LabVitalSparse.Af2H: ds_case_split_cf: ['LabVitalSparse.Af2H.timestep', 'LabVitalSparse.Af2H.input_ids', 'LabVitalSparse.Af2H.input_wgts', 'LabVitalSparse.Af2H.timeinfo', 'LabVitalSparse.Af2H.timevalues']\n",
      "[INFO:2024-04-21 09:21:26,205:(pipeline_dataset.py@227 recfldtkn.pipeline_dataset)]: {'inference': Dataset({\n",
      "    features: ['PID', 'ObsDT', 'TargetCGM.Bf24H.input_ids', 'TargetCGM.Af2H.input_ids', 'TimeSparse.Bf24H.timeinfo', 'TimeSparse.Bf24H.timevalues', 'TimeSparse.Af2H.timeinfo', 'TimeSparse.Af2H.timevalues', 'MedSparse.Bf24H.timestep', 'MedSparse.Bf24H.input_ids', 'MedSparse.Bf24H.input_wgts', 'MedSparse.Bf24H.timeinfo', 'MedSparse.Bf24H.timevalues', 'MedSparse.Af2H.timestep', 'MedSparse.Af2H.input_ids', 'MedSparse.Af2H.input_wgts', 'MedSparse.Af2H.timeinfo', 'MedSparse.Af2H.timevalues', 'EduSparse.Bf24H.timestep', 'EduSparse.Bf24H.input_ids', 'EduSparse.Bf24H.input_wgts', 'EduSparse.Bf24H.timeinfo', 'EduSparse.Bf24H.timevalues', 'EduSparse.Af2H.timestep', 'EduSparse.Af2H.input_ids', 'EduSparse.Af2H.input_wgts', 'EduSparse.Af2H.timeinfo', 'EduSparse.Af2H.timevalues', 'DietSparse.Bf24H.timestep', 'DietSparse.Bf24H.input_ids', 'DietSparse.Bf24H.input_wgts', 'DietSparse.Bf24H.timeinfo', 'DietSparse.Bf24H.timevalues', 'DietSparse.Af2H.timestep', 'DietSparse.Af2H.input_ids', 'DietSparse.Af2H.input_wgts', 'DietSparse.Af2H.timeinfo', 'DietSparse.Af2H.timevalues', 'ActivitySparse.Bf24H.timestep', 'ActivitySparse.Bf24H.input_ids', 'ActivitySparse.Bf24H.input_wgts', 'ActivitySparse.Bf24H.timeinfo', 'ActivitySparse.Bf24H.timevalues', 'ActivitySparse.Af2H.timestep', 'ActivitySparse.Af2H.input_ids', 'ActivitySparse.Af2H.input_wgts', 'ActivitySparse.Af2H.timeinfo', 'ActivitySparse.Af2H.timevalues', 'LabVitalSparse.Bf24H.timestep', 'LabVitalSparse.Bf24H.input_ids', 'LabVitalSparse.Bf24H.input_wgts', 'LabVitalSparse.Bf24H.timeinfo', 'LabVitalSparse.Bf24H.timevalues', 'LabVitalSparse.Af2H.timestep', 'LabVitalSparse.Af2H.input_ids', 'LabVitalSparse.Af2H.input_wgts', 'LabVitalSparse.Af2H.timeinfo', 'LabVitalSparse.Af2H.timevalues'],\n",
      "    num_rows: 75\n",
      "})}\n",
      "[INFO:2024-04-21 09:21:26,206:(pipeline_dataset.py@228 recfldtkn.pipeline_dataset)]: -------------- Done --------------\n"
     ]
    }
   ],
   "source": [
    "DataResults = pipeline_to_generate_dfcase_and_dataset(RecName_to_dsRec, \n",
    "                                                     RecName_to_dsRecInfo,\n",
    "\n",
    "                                                    # df_case\n",
    "                                                    InputCaseSetName,\n",
    "                                                    TriggerCaseMethod,\n",
    "                                                    TagMethod_List,\n",
    "                                                    FilterMethod_List,\n",
    "                                                    SplitDict,\n",
    "                                                \n",
    "                                                    # ds_case\n",
    "                                                    CaseSplitConfig,\n",
    "                                                    CaseFeat_List,\n",
    "\n",
    "                                                    # config\n",
    "                                                    cf_to_QueryCaseFeatConfig,\n",
    "                                                    cf_to_CaseFeatConfig, \n",
    "                                                    SPACE,\n",
    "                                                    cohort_args, \n",
    "                                                    cohort_label_list,\n",
    "                                                    \n",
    "                                                    # proc sets\n",
    "                                                    CASE_TAGGING_PROC_CONFIG,\n",
    "                                                    CASE_FIEDLING_PROC_CONFIG,\n",
    "                                                    SAVE_DF_CASE,\n",
    "                                                    SAVE_DS_DATA,\n",
    "                                                    LOAD_DF_CASE, \n",
    "                                                    LOAD_DS_DATA,\n",
    "                                                    RANDOM_SAMPLE,\n",
    "                                                    SAVE_TRIGGER_DF,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485e8888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['PID', 'ObsDT', 'TargetCGM.Bf24H.input_ids', 'TargetCGM.Af2H.input_ids', 'TimeSparse.Bf24H.timeinfo', 'TimeSparse.Bf24H.timevalues', 'TimeSparse.Af2H.timeinfo', 'TimeSparse.Af2H.timevalues', 'MedSparse.Bf24H.timestep', 'MedSparse.Bf24H.input_ids', 'MedSparse.Bf24H.input_wgts', 'MedSparse.Bf24H.timeinfo', 'MedSparse.Bf24H.timevalues', 'MedSparse.Af2H.timestep', 'MedSparse.Af2H.input_ids', 'MedSparse.Af2H.input_wgts', 'MedSparse.Af2H.timeinfo', 'MedSparse.Af2H.timevalues', 'EduSparse.Bf24H.timestep', 'EduSparse.Bf24H.input_ids', 'EduSparse.Bf24H.input_wgts', 'EduSparse.Bf24H.timeinfo', 'EduSparse.Bf24H.timevalues', 'EduSparse.Af2H.timestep', 'EduSparse.Af2H.input_ids', 'EduSparse.Af2H.input_wgts', 'EduSparse.Af2H.timeinfo', 'EduSparse.Af2H.timevalues', 'DietSparse.Bf24H.timestep', 'DietSparse.Bf24H.input_ids', 'DietSparse.Bf24H.input_wgts', 'DietSparse.Bf24H.timeinfo', 'DietSparse.Bf24H.timevalues', 'DietSparse.Af2H.timestep', 'DietSparse.Af2H.input_ids', 'DietSparse.Af2H.input_wgts', 'DietSparse.Af2H.timeinfo', 'DietSparse.Af2H.timevalues', 'ActivitySparse.Bf24H.timestep', 'ActivitySparse.Bf24H.input_ids', 'ActivitySparse.Bf24H.input_wgts', 'ActivitySparse.Bf24H.timeinfo', 'ActivitySparse.Bf24H.timevalues', 'ActivitySparse.Af2H.timestep', 'ActivitySparse.Af2H.input_ids', 'ActivitySparse.Af2H.input_wgts', 'ActivitySparse.Af2H.timeinfo', 'ActivitySparse.Af2H.timevalues', 'LabVitalSparse.Bf24H.timestep', 'LabVitalSparse.Bf24H.input_ids', 'LabVitalSparse.Bf24H.input_wgts', 'LabVitalSparse.Bf24H.timeinfo', 'LabVitalSparse.Bf24H.timevalues', 'LabVitalSparse.Af2H.timestep', 'LabVitalSparse.Af2H.input_ids', 'LabVitalSparse.Af2H.input_wgts', 'LabVitalSparse.Af2H.timeinfo', 'LabVitalSparse.Af2H.timevalues'],\n",
       "    num_rows: 75\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_case_cf_dict = DataResults['ds_case_cf_dict']\n",
    "dataset = ds_case_cf_dict['inference']\n",
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea816533",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515939af",
   "metadata": {},
   "source": [
    "# EntryFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e91861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntryForCgmMedalGen\n"
     ]
    }
   ],
   "source": [
    "TASK = 'CgmMedalGen'\n",
    "ENTRY_METHOD = f'EntryFor{TASK}'\n",
    "\n",
    "EntryArgs = {\n",
    "    'Target_CFs': ['TargetCGM.Bf24H'],\n",
    "    \n",
    "    'Future_CFs': ['TargetCGM.Af2H'],\n",
    "    \n",
    "    'MEDAL_Fields': {\n",
    "        'Time': ['TimeSparse.Bf24H', 'TimeSparse.Af2H'],\n",
    "        \n",
    "        # 'Med':  ['MedSparse.Bf24H',  'MedSparse.Af2H'],\n",
    "        'Med':  ['MedSparse.Bf24H',  'Mask.MedSparse.Af2H'],\n",
    "        \n",
    "        # 'Edu': ['EduSparse.Bf24H', 'EduSparse.Af2H'],\n",
    "        'Edu': ['EduSparse.Bf24H', 'Mask.EduSparse.Af2H'],\n",
    "        \n",
    "        # 'Diet': ['DietSparse.Bf24H', 'DietSparse.Af2H'],\n",
    "        'Diet': ['DietSparse.Bf24H', 'Mask.DietSparse.Af2H'],\n",
    "        \n",
    "        # 'Activity': ['ActivitySparse.Bf24H', 'ActivitySparse.Af2H'],\n",
    "        'Activity': ['ActivitySparse.Bf24H', 'Mask.ActivitySparse.Af2H'],\n",
    "        \n",
    "        # 'Lab': ['LabVitalSparse.Bf24H', 'LabVitalSparse.Af2H'],\n",
    "        'Lab': ['LabVitalSparse.Bf24H', 'Mask.LabVitalSparse.Af2H'],\n",
    "    }, \n",
    "}\n",
    "\n",
    "\n",
    "print(ENTRY_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf77a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_to_CFVocab = DataResults['cf_to_CFVocab']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29ca1b",
   "metadata": {},
   "source": [
    "## Step 1: Mask a CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8014900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PID',\n",
       " 'ObsDT',\n",
       " 'TargetCGM.Bf24H.input_ids',\n",
       " 'TargetCGM.Af2H.input_ids',\n",
       " 'TimeSparse.Bf24H.timeinfo',\n",
       " 'TimeSparse.Bf24H.timevalues',\n",
       " 'TimeSparse.Af2H.timeinfo',\n",
       " 'TimeSparse.Af2H.timevalues',\n",
       " 'MedSparse.Bf24H.timestep',\n",
       " 'MedSparse.Bf24H.input_ids',\n",
       " 'MedSparse.Bf24H.input_wgts',\n",
       " 'MedSparse.Bf24H.timeinfo',\n",
       " 'MedSparse.Bf24H.timevalues',\n",
       " 'MedSparse.Af2H.timestep',\n",
       " 'MedSparse.Af2H.input_ids',\n",
       " 'MedSparse.Af2H.input_wgts',\n",
       " 'MedSparse.Af2H.timeinfo',\n",
       " 'MedSparse.Af2H.timevalues',\n",
       " 'EduSparse.Bf24H.timestep',\n",
       " 'EduSparse.Bf24H.input_ids',\n",
       " 'EduSparse.Bf24H.input_wgts',\n",
       " 'EduSparse.Bf24H.timeinfo',\n",
       " 'EduSparse.Bf24H.timevalues',\n",
       " 'EduSparse.Af2H.timestep',\n",
       " 'EduSparse.Af2H.input_ids',\n",
       " 'EduSparse.Af2H.input_wgts',\n",
       " 'EduSparse.Af2H.timeinfo',\n",
       " 'EduSparse.Af2H.timevalues',\n",
       " 'DietSparse.Bf24H.timestep',\n",
       " 'DietSparse.Bf24H.input_ids',\n",
       " 'DietSparse.Bf24H.input_wgts',\n",
       " 'DietSparse.Bf24H.timeinfo',\n",
       " 'DietSparse.Bf24H.timevalues',\n",
       " 'DietSparse.Af2H.timestep',\n",
       " 'DietSparse.Af2H.input_ids',\n",
       " 'DietSparse.Af2H.input_wgts',\n",
       " 'DietSparse.Af2H.timeinfo',\n",
       " 'DietSparse.Af2H.timevalues',\n",
       " 'ActivitySparse.Bf24H.timestep',\n",
       " 'ActivitySparse.Bf24H.input_ids',\n",
       " 'ActivitySparse.Bf24H.input_wgts',\n",
       " 'ActivitySparse.Bf24H.timeinfo',\n",
       " 'ActivitySparse.Bf24H.timevalues',\n",
       " 'ActivitySparse.Af2H.timestep',\n",
       " 'ActivitySparse.Af2H.input_ids',\n",
       " 'ActivitySparse.Af2H.input_wgts',\n",
       " 'ActivitySparse.Af2H.timeinfo',\n",
       " 'ActivitySparse.Af2H.timevalues',\n",
       " 'LabVitalSparse.Bf24H.timestep',\n",
       " 'LabVitalSparse.Bf24H.input_ids',\n",
       " 'LabVitalSparse.Bf24H.input_wgts',\n",
       " 'LabVitalSparse.Bf24H.timeinfo',\n",
       " 'LabVitalSparse.Bf24H.timevalues',\n",
       " 'LabVitalSparse.Af2H.timestep',\n",
       " 'LabVitalSparse.Af2H.input_ids',\n",
       " 'LabVitalSparse.Af2H.input_wgts',\n",
       " 'LabVitalSparse.Af2H.timeinfo',\n",
       " 'LabVitalSparse.Af2H.timevalues']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "examples = dataset[:4]\n",
    "\n",
    "[i for i in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5365cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0]], [[0.0]], [[0.0]], [[0.0]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples['DietSparse.Af2H.input_wgts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62ffced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "\n",
    "\n",
    "def generate_mask_cf_for_examples(examples, mask_cf):\n",
    "    cf = mask_cf.replace('Mask.', '')\n",
    "\n",
    "    assert cf + '.input_ids' in examples \n",
    "    batch_size = len(examples[cf + '.input_ids'])\n",
    "     \n",
    "    examples[mask_cf + '.input_ids'] = [  [[0 ]] ] * batch_size\n",
    "    if cf + '.input_wgts' in examples:\n",
    "        examples[mask_cf + '.input_wgts'] = [  [[0.]] ] * batch_size\n",
    "    examples[mask_cf + '.timestep'] = [ [0] ] * batch_size\n",
    "\n",
    "    examples[mask_cf + '.timeinfo' ] = examples[cf + '.timeinfo' ] \n",
    "    examples[mask_cf + '.timevalues' ] = examples[cf + '.timevalues' ] \n",
    "\n",
    "    return examples\n",
    "\n",
    "generate_mask_cf_for_examples.fn_string = inspect.getsource(generate_mask_cf_for_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c0551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mask.MedSparse.Af2H', 'Mask.EduSparse.Af2H', 'Mask.DietSparse.Af2H', 'Mask.ActivitySparse.Af2H', 'Mask.LabVitalSparse.Af2H']\n",
      "Mask.MedSparse.Af2H\n",
      "Mask.EduSparse.Af2H\n",
      "Mask.DietSparse.Af2H\n",
      "Mask.ActivitySparse.Af2H\n",
      "Mask.LabVitalSparse.Af2H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PID',\n",
       " 'ObsDT',\n",
       " 'TargetCGM.Bf24H.input_ids',\n",
       " 'TargetCGM.Af2H.input_ids',\n",
       " 'TimeSparse.Bf24H.timeinfo',\n",
       " 'TimeSparse.Bf24H.timevalues',\n",
       " 'TimeSparse.Af2H.timeinfo',\n",
       " 'TimeSparse.Af2H.timevalues',\n",
       " 'MedSparse.Bf24H.timestep',\n",
       " 'MedSparse.Bf24H.input_ids',\n",
       " 'MedSparse.Bf24H.input_wgts',\n",
       " 'MedSparse.Bf24H.timeinfo',\n",
       " 'MedSparse.Bf24H.timevalues',\n",
       " 'MedSparse.Af2H.timestep',\n",
       " 'MedSparse.Af2H.input_ids',\n",
       " 'MedSparse.Af2H.input_wgts',\n",
       " 'MedSparse.Af2H.timeinfo',\n",
       " 'MedSparse.Af2H.timevalues',\n",
       " 'EduSparse.Bf24H.timestep',\n",
       " 'EduSparse.Bf24H.input_ids',\n",
       " 'EduSparse.Bf24H.input_wgts',\n",
       " 'EduSparse.Bf24H.timeinfo',\n",
       " 'EduSparse.Bf24H.timevalues',\n",
       " 'EduSparse.Af2H.timestep',\n",
       " 'EduSparse.Af2H.input_ids',\n",
       " 'EduSparse.Af2H.input_wgts',\n",
       " 'EduSparse.Af2H.timeinfo',\n",
       " 'EduSparse.Af2H.timevalues',\n",
       " 'DietSparse.Bf24H.timestep',\n",
       " 'DietSparse.Bf24H.input_ids',\n",
       " 'DietSparse.Bf24H.input_wgts',\n",
       " 'DietSparse.Bf24H.timeinfo',\n",
       " 'DietSparse.Bf24H.timevalues',\n",
       " 'DietSparse.Af2H.timestep',\n",
       " 'DietSparse.Af2H.input_ids',\n",
       " 'DietSparse.Af2H.input_wgts',\n",
       " 'DietSparse.Af2H.timeinfo',\n",
       " 'DietSparse.Af2H.timevalues',\n",
       " 'ActivitySparse.Bf24H.timestep',\n",
       " 'ActivitySparse.Bf24H.input_ids',\n",
       " 'ActivitySparse.Bf24H.input_wgts',\n",
       " 'ActivitySparse.Bf24H.timeinfo',\n",
       " 'ActivitySparse.Bf24H.timevalues',\n",
       " 'ActivitySparse.Af2H.timestep',\n",
       " 'ActivitySparse.Af2H.input_ids',\n",
       " 'ActivitySparse.Af2H.input_wgts',\n",
       " 'ActivitySparse.Af2H.timeinfo',\n",
       " 'ActivitySparse.Af2H.timevalues',\n",
       " 'LabVitalSparse.Bf24H.timestep',\n",
       " 'LabVitalSparse.Bf24H.input_ids',\n",
       " 'LabVitalSparse.Bf24H.input_wgts',\n",
       " 'LabVitalSparse.Bf24H.timeinfo',\n",
       " 'LabVitalSparse.Bf24H.timevalues',\n",
       " 'LabVitalSparse.Af2H.timestep',\n",
       " 'LabVitalSparse.Af2H.input_ids',\n",
       " 'LabVitalSparse.Af2H.input_wgts',\n",
       " 'LabVitalSparse.Af2H.timeinfo',\n",
       " 'LabVitalSparse.Af2H.timevalues',\n",
       " 'Mask.MedSparse.Af2H.input_ids',\n",
       " 'Mask.MedSparse.Af2H.input_wgts',\n",
       " 'Mask.MedSparse.Af2H.timestep',\n",
       " 'Mask.MedSparse.Af2H.timeinfo',\n",
       " 'Mask.MedSparse.Af2H.timevalues',\n",
       " 'Mask.EduSparse.Af2H.input_ids',\n",
       " 'Mask.EduSparse.Af2H.input_wgts',\n",
       " 'Mask.EduSparse.Af2H.timestep',\n",
       " 'Mask.EduSparse.Af2H.timeinfo',\n",
       " 'Mask.EduSparse.Af2H.timevalues',\n",
       " 'Mask.DietSparse.Af2H.input_ids',\n",
       " 'Mask.DietSparse.Af2H.input_wgts',\n",
       " 'Mask.DietSparse.Af2H.timestep',\n",
       " 'Mask.DietSparse.Af2H.timeinfo',\n",
       " 'Mask.DietSparse.Af2H.timevalues',\n",
       " 'Mask.ActivitySparse.Af2H.input_ids',\n",
       " 'Mask.ActivitySparse.Af2H.input_wgts',\n",
       " 'Mask.ActivitySparse.Af2H.timestep',\n",
       " 'Mask.ActivitySparse.Af2H.timeinfo',\n",
       " 'Mask.ActivitySparse.Af2H.timevalues',\n",
       " 'Mask.LabVitalSparse.Af2H.input_ids',\n",
       " 'Mask.LabVitalSparse.Af2H.input_wgts',\n",
       " 'Mask.LabVitalSparse.Af2H.timestep',\n",
       " 'Mask.LabVitalSparse.Af2H.timeinfo',\n",
       " 'Mask.LabVitalSparse.Af2H.timevalues']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEDAL_Fields = EntryArgs['MEDAL_Fields']\n",
    "\n",
    "mask_cf_list = [cf for cf in list(itertools.chain(*[cfs for field, cfs in MEDAL_Fields.items()])) if 'Mask.' in cf]\n",
    "print(mask_cf_list)\n",
    "\n",
    "for mask_cf in mask_cf_list:\n",
    "    print(mask_cf)\n",
    "    examples = generate_mask_cf_for_examples(examples, mask_cf)\n",
    "    \n",
    "[i for i in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b929a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]], [[0]], [[0]], [[0]]]\n",
      "[[[0]], [[0]], [[0]], [[0]]]\n"
     ]
    }
   ],
   "source": [
    "a = examples['Mask.DietSparse.Af2H.input_ids']\n",
    "# examples\n",
    "b = examples['DietSparse.Af2H.input_ids']\n",
    "# examples\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f4b8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.0]], [[0.0]], [[0.0]], [[0.0]]]\n",
      "[[[0.0]], [[0.0]], [[0.0]], [[0.0]]]\n"
     ]
    }
   ],
   "source": [
    "a = examples['Mask.DietSparse.Af2H.input_wgts']\n",
    "# examples\n",
    "b = examples['DietSparse.Af2H.input_wgts']\n",
    "# examples\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97e472ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0], [0], [0]]\n",
      "[[0], [0], [0], [0]]\n"
     ]
    }
   ],
   "source": [
    "a = examples['Mask.DietSparse.Af2H.timestep']\n",
    "# examples\n",
    "b = examples['DietSparse.Af2H.timestep']\n",
    "# examples\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a99e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2021-05-31T00:00:00', '5Min', '5', 'minutes', '1:To:24'], ['2021-06-12T00:00:00', '5Min', '5', 'minutes', '1:To:24'], ['2021-08-23T00:00:00', '5Min', '5', 'minutes', '1:To:24'], ['2021-09-03T00:00:00', '5Min', '5', 'minutes', '1:To:24']]\n",
      "[['2021-05-31T00:00:00', '5Min', '5', 'minutes', '1:To:24'], ['2021-06-12T00:00:00', '5Min', '5', 'minutes', '1:To:24'], ['2021-08-23T00:00:00', '5Min', '5', 'minutes', '1:To:24'], ['2021-09-03T00:00:00', '5Min', '5', 'minutes', '1:To:24']]\n"
     ]
    }
   ],
   "source": [
    "a = examples['Mask.DietSparse.Af2H.timevalues']\n",
    "# examples\n",
    "b = examples['DietSparse.Af2H.timevalues']\n",
    "# examples\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d51a094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_to_CFVocab = DataResults['cf_to_CFVocab']\n",
    "\n",
    "\n",
    "for mask_cf in mask_cf_list:\n",
    "    cf_to_CFVocab[mask_cf] = cf_to_CFVocab[mask_cf.replace('Mask.', '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cbcad3",
   "metadata": {},
   "source": [
    "## Step 2: Sparse to Dense Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebe70342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "\n",
    "def update_emptiness_of_examples(x, cf):\n",
    "    # print(x)\n",
    "    # print(cf)\n",
    "    EmptyFlag = False\n",
    "    values = x[cf + '.input_ids']\n",
    "    # print(values[0][0])\n",
    "    # print(values[0][0] == 0)\n",
    "    # print(int(values[0][0]) == 0)\n",
    "    # print(values)\n",
    "    # print(len(values) == 1)\n",
    "    # print(len(values[0]) == 1)\n",
    "    # print(int(values[0][0]) == 0)\n",
    "    if len(values) == 1 and len(values[0]) == 1 and int(values[0][0]) == 0:\n",
    "        EmptyFlag = True\n",
    "    \n",
    "    # print('EmptyFlag', EmptyFlag)\n",
    "    d = {}\n",
    "    d[cf + '.input_ids'] = [] if EmptyFlag == True else x[cf + '.input_ids']\n",
    "    if cf + '.input_wgts' in x:\n",
    "        d[cf + '.input_wgts'] = [] if EmptyFlag == True else x[cf + '.input_wgts']\n",
    "    d[cf + '.timestep'] = [] if EmptyFlag == True else x[cf + '.timestep']\n",
    "    \n",
    "    return d\n",
    "                \n",
    "update_emptiness_of_examples.fn_string = inspect.getsource(update_emptiness_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4002e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "\n",
    "def process_field_vocab(Field, MEDAL_Fields, cf_to_CFVocab):\n",
    "\n",
    "    Vocab = {}\n",
    "\n",
    "    MEDAL_CFs = MEDAL_Fields[Field]\n",
    "    # adding input_ids and input_wgts\n",
    "    Vocab['input_ids']  = cf_to_CFVocab[MEDAL_CFs[0]]['input_ids']\n",
    "    Vocab['input_wgts'] = cf_to_CFVocab[MEDAL_CFs[0]]['input_wgts']\n",
    "\n",
    "    # adding timestep_ids\n",
    "    cf_to_CFVocab_timestep = {cf: cf_to_CFVocab[cf]['timestep_ids'] for cf in MEDAL_CFs}\n",
    "    COMMON_TOKEN_list = ['[PAD]', '[UNK]', '[CLS]', '[SEP]', ]\n",
    "    idx2tkn_all = COMMON_TOKEN_list + [i.split(':')[-1] for i in list(itertools.chain(*[list(cf_to_CFVocab_timestep[cf]['tkn2tid'].keys()) for cf in MEDAL_CFs]))]\n",
    "    assert len(idx2tkn_all) == len(set(idx2tkn_all))\n",
    "    tid2tkn_all = {i: tkn for i, tkn in enumerate(idx2tkn_all)}\n",
    "    tkn2tid_all = {tkn: i for i, tkn in enumerate(idx2tkn_all)}\n",
    "    Vocab['timestep_ids'] = {'tid2tkn': tid2tkn_all, 'tkn2tid': tkn2tid_all}\n",
    "    return Vocab\n",
    "\n",
    "process_field_vocab.fn_string = inspect.getsource(process_field_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca58325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "\n",
    "def process_field_input_ids(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab):\n",
    "\n",
    "    field_info = {}\n",
    "    MEDAL_CFs = MEDAL_Fields[Field]\n",
    "\n",
    "\n",
    "    seqtype = 'input_ids'\n",
    "    df = pd.DataFrame({cf: examples[cf + f'.{seqtype}'] for cf in MEDAL_CFs})\n",
    "    df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "    lst = df[seqtype].to_list()\n",
    "    # lst = pad_with_numpy(lst)\n",
    "    field_info[seqtype] = lst\n",
    "    \n",
    "    seqtype = 'input_wgts'\n",
    "    if examples[MEDAL_CFs[0] + f'.{seqtype}'][0] is None:\n",
    "        lst = None \n",
    "        # print(lst, 'no wgt is available, or all wgt are 1')\n",
    "    else:\n",
    "        df = pd.DataFrame({cf: examples[cf + f'.{seqtype}'] for cf in MEDAL_CFs})\n",
    "        df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "        lst = df[seqtype].to_list()\n",
    "        # lst = pad_with_numpy(lst)\n",
    "        # print(lst.shape)\n",
    "    field_info[seqtype] = lst\n",
    "\n",
    "    seqtype = 'timestep'\n",
    "    df = pd.DataFrame({cf: examples[cf + f'.{seqtype}'] for cf in MEDAL_CFs})\n",
    "    df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "        \n",
    "    lst = df[seqtype].to_list()\n",
    "    field_info[seqtype] = lst\n",
    "    \n",
    "    return field_info\n",
    "\n",
    "\n",
    "process_field_input_ids.fn_string = inspect.getsource(process_field_input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada09611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect \n",
    "\n",
    "def get_timesteps_info(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab):\n",
    "\n",
    "    FieldVocab = field_to_Vocab[Field]\n",
    "    field_list = MEDAL_Fields[Field]\n",
    "    total_index_list = []\n",
    "    total_timedelta_info = []\n",
    "\n",
    "    TimeUnit = None\n",
    "    TimeStep = None\n",
    "    for field in field_list:\n",
    "        timeinfo_col = f'{field}.timeinfo'\n",
    "        timevalues_col = f'{field}.timevalues'\n",
    "        d = dict(zip(examples[timeinfo_col][0], examples[timevalues_col][0]))\n",
    "        # if TimeUnit is not None:\n",
    "        #     TimeUnit = d['TimeUnit']\n",
    "        # else:\n",
    "        #     assert TimeUnit == d['TimeUnit']\n",
    "        # print(d)\n",
    "        TimeUnit = d['TimeUnit'] \n",
    "        TimeStep = d['TimeStepSize']\n",
    "        \n",
    "\n",
    "        TimeStepType = d['TimeStepType']\n",
    "        StartIdx_To_EndIdx_columns = [i for i in d if 'StartIdx-To-EndIdx' in i]\n",
    "        \n",
    "        for StartIdx_To_EndIdx_col in StartIdx_To_EndIdx_columns:\n",
    "            start_to_end = d[StartIdx_To_EndIdx_col].split(':To:')\n",
    "            StartIdx = int(start_to_end[0])\n",
    "            EndIdx   = int(start_to_end[1])\n",
    "            index_list = [f'{TimeStepType}_{i}' for i in list(range(StartIdx, EndIdx + 1))]\n",
    "            timedelta_info = [(TimeStep, TimeUnit)] * len(index_list)\n",
    "            total_index_list = total_index_list + index_list\n",
    "            total_timedelta_info = total_timedelta_info + timedelta_info\n",
    "\n",
    "            \n",
    "    timesteps = total_index_list\n",
    "    timestep_ids = [FieldVocab['timestep_ids']['tkn2tid'][i] for i in total_index_list]\n",
    "    timesteps_orig_ids = [int(i.split('_')[-1]) for i in timesteps]\n",
    "\n",
    "    timestep_info = {\n",
    "        'timesteps': timesteps,\n",
    "        'timestep_ids': timestep_ids, \n",
    "        'timesteps_orig_ids': timesteps_orig_ids, \n",
    "        'total_timedelta_info': total_timedelta_info,\n",
    "    }\n",
    "    return timestep_info\n",
    "\n",
    "get_timesteps_info.fn_string = inspect.getsource(get_timesteps_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0065ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_seqtype_base_on_timestep(single_data_point, default_template_dict, timestep_info):\n",
    "\n",
    "    default_template_dict = default_template_dict.copy()\n",
    "\n",
    "    timesteps_orig_ids = timestep_info['timesteps_orig_ids']\n",
    "    \n",
    "    updated_data_point = {}\n",
    "\n",
    "    timestep = single_data_point['timestep']\n",
    "\n",
    "    seqtype = 'input_ids'\n",
    "    seqtype_values = single_data_point[seqtype]\n",
    "    seqtype_values_template = default_template_dict[seqtype]\n",
    "    for idx, timestep_id in enumerate(timestep):\n",
    "        tensor_loc_idx = timesteps_orig_ids.index(timestep_id)\n",
    "        # print(idx, timestep_id, tensor_loc_idx)\n",
    "        seqtype_values_template[tensor_loc_idx] = seqtype_values[idx]\n",
    "        # print(seqtype_values[idx])\n",
    "        # print(tensor_loc_idx)\n",
    "        # print(seqtype_values_template[tensor_loc_idx])\n",
    "\n",
    "    updated_data_point[seqtype] = seqtype_values_template\n",
    "\n",
    "    seqtype = 'input_wgts'\n",
    "    seqtype_values = single_data_point[seqtype]\n",
    "    seqtype_values_template = default_template_dict[seqtype]\n",
    "    for idx, timestep_id in enumerate(timestep):\n",
    "        seqtype_values_template[timestep_id] = seqtype_values[idx]\n",
    "    # updated_data_point[seqtype] = pad_with_numpy(seqtype_values_template)\n",
    "    updated_data_point[seqtype] = seqtype_values_template\n",
    "\n",
    "    # updated_data_point['timestep_ids'] = pad_with_numpy(default_template_dict['timestep_ids'])\n",
    "    updated_data_point['timestep_ids'] = default_template_dict['timestep_ids']\n",
    "    return updated_data_point\n",
    "\n",
    "update_seqtype_base_on_timestep.fn_string = inspect.getsource(update_seqtype_base_on_timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd6546f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "import numpy as np \n",
    "\n",
    "def pad_with_numpy(lst, fill_value=0):\n",
    "    # Base case: Assume all elements at the deepest level are numbers\n",
    "    while isinstance(lst[0], list):\n",
    "        max_len = max(len(x) for x in lst)\n",
    "        lst = [x + [fill_value] * (max_len - len(x)) for x in lst]\n",
    "        lst = [pad_with_numpy(x, fill_value) for x in lst]\n",
    "    # Convert list to array\n",
    "    return np.array(lst)\n",
    "\n",
    "pad_with_numpy.fn_string = inspect.getsource(pad_with_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4177b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "\n",
    "import inspect \n",
    "\n",
    "def extract_datetime_components_as_list(dt):\n",
    "    return [\n",
    "        # f'Y{dt.year}',\n",
    "        f'Mon{dt.month}',\n",
    "        f'WOY{dt.isocalendar().week}',\n",
    "        f'Weekday{dt.weekday()}',\n",
    "        f'Hour{dt.hour}',\n",
    "        f'Min{dt.minute}',\n",
    "        f'Sec{dt.second}'\n",
    "    ]\n",
    "extract_datetime_components_as_list.fn_string = inspect.getsource(extract_datetime_components_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63af33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Context Variables\n",
    "###\n",
    "\n",
    "Target_CFs = EntryArgs['Target_CFs']\n",
    "MEDAL_Fields = EntryArgs['MEDAL_Fields']\n",
    "\n",
    "\n",
    "field_to_Vocab = {}\n",
    "for Field in MEDAL_Fields:\n",
    "    field_to_Vocab[Field] = process_field_vocab(Field, MEDAL_Fields, cf_to_CFVocab) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eba01f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target_CFs': ['TargetCGM.Bf24H'],\n",
       " 'Future_CFs': ['TargetCGM.Af2H'],\n",
       " 'MEDAL_Fields': {'Time': ['TimeSparse.Bf24H', 'TimeSparse.Af2H'],\n",
       "  'Med': ['MedSparse.Bf24H', 'Mask.MedSparse.Af2H'],\n",
       "  'Edu': ['EduSparse.Bf24H', 'Mask.EduSparse.Af2H'],\n",
       "  'Diet': ['DietSparse.Bf24H', 'Mask.DietSparse.Af2H'],\n",
       "  'Activity': ['ActivitySparse.Bf24H', 'Mask.ActivitySparse.Af2H'],\n",
       "  'Lab': ['LabVitalSparse.Bf24H', 'Mask.LabVitalSparse.Af2H']}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb151ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fn(examples):\n",
    "\n",
    "    \n",
    "    # MEDAL_Fields = EntryArgs['MEDAL_Fields']\n",
    "    # mask_cf_list = [cf for cf in list(itertools.chain(*[cfs for field, cfs in MEDAL_Fields.items()])) if 'Mask.' in cf]\n",
    "    # print(mask_cf_list)\n",
    "\n",
    "    for mask_cf in mask_cf_list:\n",
    "        # print(mask_cf)\n",
    "        examples = generate_mask_cf_for_examples(examples, mask_cf)\n",
    "        \n",
    "    examples_tfm = {}\n",
    "\n",
    "    ################# Target's input_ids \n",
    "    Target_CFs = EntryArgs['Target_CFs']\n",
    "    df = pd.DataFrame({cf: examples[cf + '.input_ids'] for cf in Target_CFs})\n",
    "    df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "    # examples_tfm['input_ids'] = torch.LongTensor(    np.array(df['input_ids'].to_list()    )) # ().copy()\n",
    "    examples_tfm['input_ids'] = np.array(df['input_ids'].to_list()    ) # ().copy()\n",
    "    \n",
    "    ################# Future's labels \n",
    "    Future_CFs = EntryArgs.get('Future_CFs', [])\n",
    "    if len(Future_CFs) > 0: # is not None:\n",
    "        df = pd.DataFrame({cf: examples[cf + '.input_ids'] for cf in Future_CFs})\n",
    "        df['labels'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "        # examples_tfm['labels']    = torch.LongTensor(    np.array(df['labels'].to_list()    ))\n",
    "        examples_tfm['labels']    = np.array(df['labels'].to_list()    )\n",
    "\n",
    "\n",
    "    total_fields_tfm = {}\n",
    "    ################# Target's input_ids and labels\n",
    "    for Field in MEDAL_Fields: \n",
    "\n",
    "        if Field != 'Time':\n",
    "            # print(MEDAL_Fields[Field])\n",
    "            field_info = process_field_input_ids(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab)\n",
    "            timestep_info   = get_timesteps_info(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab)\n",
    "            timestep_ids = timestep_info['timestep_ids']\n",
    "            UNK_ID = 1; PAD_ID = 0\n",
    "            default_template_dict = {\n",
    "                'input_ids':  [[UNK_ID]] * len(timestep_ids),\n",
    "                'input_wgts': [[1]     ] * len(timestep_ids), \n",
    "                'timestep_ids': timestep_ids.copy()\n",
    "            }\n",
    "            df = pd.DataFrame(field_info)\n",
    "            li = df.apply(lambda x: update_seqtype_base_on_timestep(x, default_template_dict, timestep_info), axis = 1)\n",
    "            field_info_final = pd.DataFrame(li.to_list()).to_dict(orient = 'list')\n",
    "            for k, v in field_info_final.items():\n",
    "                # print(k, pad_with_numpy(v).shape)\n",
    "                if '_wgts' not in k:\n",
    "                    # field_info_final[k] = torch.LongTensor(pad_with_numpy(v))\n",
    "                    field_info_final[k] = pad_with_numpy(v)\n",
    "                else:\n",
    "                    # field_info_final[k] = torch.FloatTensor(pad_with_numpy(v))\n",
    "                    field_info_final[k] = pad_with_numpy(v)\n",
    "            total_fields_tfm[f'Field_{Field}'] = field_info_final\n",
    "\n",
    "            \n",
    "        elif Field == 'Time':\n",
    "\n",
    "            timestep_info = get_timesteps_info(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab)\n",
    "            timesteps_orig_ids = timestep_info['timesteps_orig_ids']\n",
    "            timedelta_info = timestep_info['total_timedelta_info']\n",
    "\n",
    "            d = {\n",
    "                'ObsDT': examples['ObsDT'], \n",
    "                'timesteps_orig_ids': [timesteps_orig_ids] * len(examples['ObsDT']), \n",
    "                'timedelta_info': [timedelta_info] * len(examples['ObsDT']),\n",
    "                'timestep_ids': [timestep_info['timestep_ids']] * len(examples['ObsDT'])\n",
    "            }\n",
    "            df = pd.DataFrame(d)\n",
    "            df['datetime'] = df.apply(lambda x: [x['ObsDT'] + pd.Timedelta(i*int(delta[0]), unit=delta[-1]) \n",
    "                                                for i, delta in zip(x['timesteps_orig_ids'], x['timedelta_info'])], axis=1)\n",
    "            df['inputs'] = df['datetime'].apply(lambda x: [extract_datetime_components_as_list(i) for i in x])\n",
    "            df['input_ids'] = df['inputs'].apply(lambda x: [[field_to_Vocab[Field]['input_ids']['tkn2tid'][j] for j in i] for i in x])\n",
    "\n",
    "            field_info_final = df[['input_ids', 'timestep_ids']].to_dict(orient='list')\n",
    "            for k, v in field_info_final.items():\n",
    "                # print(k, pad_with_numpy(v).shape)\n",
    "                # field_info_final[k] = pad_with_numpy(v)\n",
    "                # field_info_final[k] = torch.LongTensor(pad_with_numpy(v))\n",
    "                field_info_final[k] = pad_with_numpy(v)\n",
    "                \n",
    "\n",
    "            total_fields_tfm[f'Field_{Field}'] = field_info_final\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Field: {Field}\")\n",
    "        \n",
    "    examples_tfm['total_field_info'] = total_fields_tfm\n",
    "    return examples_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a51491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[115, 115, 114, ..., 158, 154, 149],\n",
       "        [111, 110, 109, ..., 122, 122, 123],\n",
       "        [ 89,  89,  90, ...,  94,  94,  94],\n",
       "        [192, 195, 198, ..., 209, 199, 197]]),\n",
       " 'labels': array([[145, 140, 136, 133, 131, 128, 126, 125, 125, 127, 129, 130, 131,\n",
       "         131, 131, 130, 129, 129, 128, 128, 128, 129, 129, 128],\n",
       "        [124, 125, 127, 128, 129, 129, 129, 129, 129, 129, 129, 126, 125,\n",
       "         123, 123, 122, 123, 124, 124, 123, 121, 120, 119, 118],\n",
       "        [ 93,  93,  94,  94,  93,  93,  93,  94,  94,  93,  93,  93,  94,\n",
       "          96,  96,  97,  97,  97,  95,  94,  92,  92,  92,  93],\n",
       "        [196, 195, 195, 195, 193, 184, 169, 149, 129, 114, 110, 110, 112,\n",
       "         117, 132, 145, 153, 151, 147, 143, 141, 145, 148, 150]]),\n",
       " 'total_field_info': {'Field_Time': {'input_ids': array([[[ 12,  40,  79,  80, 104, 164],\n",
       "           [ 12,  40,  79,  80, 109, 164],\n",
       "           [ 12,  40,  79,  80, 114, 164],\n",
       "           ...,\n",
       "           [ 12,  41,  73,  81, 154, 164],\n",
       "           [ 12,  41,  73,  81, 159, 164],\n",
       "           [ 12,  41,  73,  82, 104, 164]],\n",
       "   \n",
       "          [[ 13,  42,  77,  80, 104, 164],\n",
       "           [ 13,  42,  77,  80, 109, 164],\n",
       "           [ 13,  42,  77,  80, 114, 164],\n",
       "           ...,\n",
       "           [ 13,  42,  78,  81, 154, 164],\n",
       "           [ 13,  42,  78,  81, 159, 164],\n",
       "           [ 13,  42,  78,  82, 104, 164]],\n",
       "   \n",
       "          [[ 15,  52,  79,  80, 104, 164],\n",
       "           [ 15,  52,  79,  80, 109, 164],\n",
       "           [ 15,  52,  79,  80, 114, 164],\n",
       "           ...,\n",
       "           [ 15,  53,  73,  81, 154, 164],\n",
       "           [ 15,  53,  73,  81, 159, 164],\n",
       "           [ 15,  53,  73,  82, 104, 164]],\n",
       "   \n",
       "          [[ 16,  54,  76,  80, 104, 164],\n",
       "           [ 16,  54,  76,  80, 109, 164],\n",
       "           [ 16,  54,  76,  80, 114, 164],\n",
       "           ...,\n",
       "           [ 16,  54,  77,  81, 154, 164],\n",
       "           [ 16,  54,  77,  81, 159, 164],\n",
       "           [ 16,  54,  77,  82, 104, 164]]]),\n",
       "   'timestep_ids': array([[  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316]])},\n",
       "  'Field_Med': {'input_ids': array([[[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]]]),\n",
       "   'input_wgts': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]]]),\n",
       "   'timestep_ids': array([[  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316]])},\n",
       "  'Field_Edu': {'input_ids': array([[[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]],\n",
       "   \n",
       "          [[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]],\n",
       "   \n",
       "          [[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]],\n",
       "   \n",
       "          [[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]]]),\n",
       "   'input_wgts': array([[[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]],\n",
       "   \n",
       "          [[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]],\n",
       "   \n",
       "          [[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]],\n",
       "   \n",
       "          [[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]]]),\n",
       "   'timestep_ids': array([[  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316]])},\n",
       "  'Field_Diet': {'input_ids': array([[[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]]]),\n",
       "   'input_wgts': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]]]),\n",
       "   'timestep_ids': array([[  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316]])},\n",
       "  'Field_Activity': {'input_ids': array([[[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0],\n",
       "           [1, 0, 0, ..., 0, 0, 0]]]),\n",
       "   'input_wgts': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]],\n",
       "   \n",
       "          [[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.],\n",
       "           [1., 0., 0., ..., 0., 0., 0.]]]),\n",
       "   'timestep_ids': array([[  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316]])},\n",
       "  'Field_Lab': {'input_ids': array([[[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]],\n",
       "   \n",
       "          [[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]],\n",
       "   \n",
       "          [[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]],\n",
       "   \n",
       "          [[1],\n",
       "           [1],\n",
       "           [1],\n",
       "           ...,\n",
       "           [1],\n",
       "           [1],\n",
       "           [1]]]),\n",
       "   'input_wgts': array([[[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]],\n",
       "   \n",
       "          [[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]],\n",
       "   \n",
       "          [[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]],\n",
       "   \n",
       "          [[0.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]]]),\n",
       "   'timestep_ids': array([[  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316],\n",
       "          [  4,   5,   6, ..., 314, 315, 316]])}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_tfm = transform_fn(examples)\n",
    "examples_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "878854c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'labels', 'total_field_info']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in examples_tfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c23ccf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 289)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_tfm['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d6d9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_tfm['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84de8f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Target_CFs', 'Future_CFs', 'MEDAL_Fields']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in EntryArgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "116690bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids (4, 313, 6)\n",
      "timestep_ids (4, 313)\n",
      "input_ids (4, 313, 136)\n",
      "input_wgts (4, 313, 136)\n",
      "timestep_ids (4, 313)\n",
      "input_ids (4, 313, 1)\n",
      "input_wgts (4, 313, 1)\n",
      "timestep_ids (4, 313)\n",
      "input_ids (4, 313, 122)\n",
      "input_wgts (4, 313, 122)\n",
      "timestep_ids (4, 313)\n",
      "input_ids (4, 313, 7)\n",
      "input_wgts (4, 313, 7)\n",
      "timestep_ids (4, 313)\n",
      "input_ids (4, 313, 1)\n",
      "input_wgts (4, 313, 1)\n",
      "timestep_ids (4, 313)\n"
     ]
    }
   ],
   "source": [
    "fields = EntryArgs['MEDAL_Fields']\n",
    "# fields\n",
    "\n",
    "for field in fields:\n",
    "    for k, v in examples_tfm['total_field_info'][f'Field_{field}'].items():\n",
    "        print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce7c12",
   "metadata": {},
   "source": [
    "## Step 7: Final Entry Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7268e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pipeline\\fn_learning\\EntryForCgmMedalGen.py\n"
     ]
    }
   ],
   "source": [
    "import inspect \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import itertools\n",
    "import torch\n",
    "from recfldtkn.loadtools import convert_variables_to_pystirng\n",
    "\n",
    "\n",
    "def fn_entry_method_for_finaldata(dataset, cf_to_CFVocab, EntryArgs):\n",
    "    \n",
    "    ###########################\n",
    "    Target_CFs = EntryArgs['Target_CFs']\n",
    "    MEDAL_Fields = EntryArgs['MEDAL_Fields']\n",
    "    mask_cf_list = [cf for cf in list(itertools.chain(*[cfs for field, cfs in MEDAL_Fields.items()])) if 'Mask.' in cf]\n",
    "    for mask_cf in mask_cf_list:\n",
    "        cf_to_CFVocab[mask_cf] = cf_to_CFVocab[mask_cf.replace('Mask.', '')]\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    field_to_Vocab = {}\n",
    "    for Field in MEDAL_Fields:\n",
    "        field_to_Vocab[Field] = process_field_vocab(Field, MEDAL_Fields, cf_to_CFVocab) \n",
    "\n",
    "\n",
    "    def transform_fn(examples):\n",
    "\n",
    "        for mask_cf in mask_cf_list:\n",
    "            examples = generate_mask_cf_for_examples(examples, mask_cf)\n",
    "\n",
    "        examples_tfm = {}\n",
    "        \n",
    "        \n",
    "        ################# Target's input_ids \n",
    "        Target_CFs = EntryArgs['Target_CFs']\n",
    "        df = pd.DataFrame({cf: examples[cf + '.input_ids'] for cf in Target_CFs})\n",
    "        df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "        examples_tfm['input_ids'] = torch.LongTensor(    np.array(df['input_ids'].to_list()    )) # ().copy()\n",
    "        # examples_tfm['input_ids'] = np.array(df['input_ids'].to_list()    ) # ().copy()\n",
    "        \n",
    "        ################# Future's labels \n",
    "        Future_CFs = EntryArgs.get('Future_CFs', [])\n",
    "        if len(Future_CFs) > 0: # is not None:\n",
    "            df = pd.DataFrame({cf: examples[cf + '.input_ids'] for cf in Future_CFs})\n",
    "            df['labels'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "            examples_tfm['labels'] = torch.LongTensor(    np.array(df['labels'].to_list()    ))\n",
    "            # examples_tfm['labels']    = np.array(df['labels'].to_list()    )\n",
    "\n",
    "        total_fields_tfm = {}\n",
    "        ################# Target's input_ids and labels\n",
    "        for Field in MEDAL_Fields: \n",
    "\n",
    "            if Field != 'Time':\n",
    "                field_info = process_field_input_ids(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab)\n",
    "                timestep_info   = get_timesteps_info(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab)\n",
    "                timestep_ids = timestep_info['timestep_ids']\n",
    "                UNK_ID = 1; PAD_ID = 0\n",
    "                default_template_dict = {\n",
    "                    'input_ids':  [[UNK_ID]] * len(timestep_ids),\n",
    "                    'input_wgts': [[1]     ] * len(timestep_ids), \n",
    "                    'timestep_ids': timestep_ids.copy()\n",
    "                }\n",
    "                df = pd.DataFrame(field_info)\n",
    "                li = df.apply(lambda x: update_seqtype_base_on_timestep(x, default_template_dict, timestep_info), axis = 1)\n",
    "                field_info_final = pd.DataFrame(li.to_list()).to_dict(orient = 'list')\n",
    "                for k, v in field_info_final.items():\n",
    "                    # print(k, pad_with_numpy(v).shape)\n",
    "                    if '_wgts' not in k:\n",
    "                        field_info_final[k] = torch.LongTensor(pad_with_numpy(v))\n",
    "                        # field_info_final[k] = pad_with_numpy(v)\n",
    "                    else:\n",
    "                        field_info_final[k] = torch.Tensor(pad_with_numpy(v))\n",
    "                        # field_info_final[k] = pad_with_numpy(v)\n",
    "                total_fields_tfm[f'Field_{Field}'] = field_info_final\n",
    "\n",
    "                \n",
    "            elif Field == 'Time':\n",
    "\n",
    "                timestep_info = get_timesteps_info(examples, Field, MEDAL_Fields, field_to_Vocab, cf_to_CFVocab)\n",
    "                timesteps_orig_ids = timestep_info['timesteps_orig_ids']\n",
    "                timedelta_info = timestep_info['total_timedelta_info']\n",
    "\n",
    "                d = {\n",
    "                    'ObsDT': examples['ObsDT'], \n",
    "                    'timesteps_orig_ids': [timesteps_orig_ids] * len(examples['ObsDT']), \n",
    "                    'timedelta_info': [timedelta_info] * len(examples['ObsDT']),\n",
    "                    'timestep_ids': [timestep_info['timestep_ids']] * len(examples['ObsDT'])\n",
    "                }\n",
    "                df = pd.DataFrame(d)\n",
    "                df['datetime'] = df.apply(lambda x: [x['ObsDT'] + pd.Timedelta(i*int(delta[0]), unit=delta[-1]) \n",
    "                                                    for i, delta in zip(x['timesteps_orig_ids'], x['timedelta_info'])], axis=1)\n",
    "                df['inputs'] = df['datetime'].apply(lambda x: [extract_datetime_components_as_list(i) for i in x])\n",
    "                df['input_ids'] = df['inputs'].apply(lambda x: [[field_to_Vocab[Field]['input_ids']['tkn2tid'][j] for j in i] for i in x])\n",
    "\n",
    "                field_info_final = df[['input_ids', 'timestep_ids']].to_dict(orient='list')\n",
    "                for k, v in field_info_final.items():\n",
    "                    # print(k, pad_with_numpy(v).shape)\n",
    "                    # field_info_final[k] = pad_with_numpy(v)\n",
    "                    field_info_final[k] = torch.LongTensor(pad_with_numpy(v))\n",
    "                    # field_info_final[k] = pad_with_numpy(v)\n",
    "                    \n",
    "\n",
    "                total_fields_tfm[f'Field_{Field}'] = field_info_final\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid Field: {Field}\")\n",
    "            \n",
    "        examples_tfm['total_field_info'] = total_fields_tfm\n",
    "        return examples_tfm\n",
    "    \n",
    "    dataset.set_transform(transform_fn)\n",
    "    results = {'dataset': dataset, 'field_to_Vocab': field_to_Vocab}\n",
    "    return results\n",
    "\n",
    "\n",
    "fn_entry_method_for_finaldata.fn_string = inspect.getsource(fn_entry_method_for_finaldata)\n",
    "\n",
    "\n",
    "prefix = ['import pandas as pd', \n",
    "          'import numpy as np',\n",
    "          'import itertools',\n",
    "          'import torch',\n",
    "          ]\n",
    "fn_variables = [\n",
    "    pad_with_numpy,\n",
    "    generate_mask_cf_for_examples,\n",
    "    process_field_vocab, \n",
    "    process_field_input_ids,\n",
    "    get_timesteps_info,\n",
    "    update_seqtype_base_on_timestep,\n",
    "    extract_datetime_components_as_list,\n",
    "    fn_entry_method_for_finaldata,\n",
    "    ]\n",
    "pycode = convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "pypath = os.path.join(SPACE['CODE_FN'], 'fn_learning', f'{ENTRY_METHOD}.py')\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0c49281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': ['TimeSparse.Bf24H', 'TimeSparse.Af2H'],\n",
       " 'Med': ['MedSparse.Bf24H', 'Mask.MedSparse.Af2H'],\n",
       " 'Edu': ['EduSparse.Bf24H', 'Mask.EduSparse.Af2H'],\n",
       " 'Diet': ['DietSparse.Bf24H', 'Mask.DietSparse.Af2H'],\n",
       " 'Activity': ['ActivitySparse.Bf24H', 'Mask.ActivitySparse.Af2H'],\n",
       " 'Lab': ['LabVitalSparse.Bf24H', 'Mask.LabVitalSparse.Af2H']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EntryArgs['MEDAL_Fields']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cd94e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['PID', 'ObsDT', 'TargetCGM.Bf24H.input_ids', 'TargetCGM.Af2H.input_ids', 'TimeSparse.Bf24H.timeinfo', 'TimeSparse.Bf24H.timevalues', 'TimeSparse.Af2H.timeinfo', 'TimeSparse.Af2H.timevalues', 'MedSparse.Bf24H.timestep', 'MedSparse.Bf24H.input_ids', 'MedSparse.Bf24H.input_wgts', 'MedSparse.Bf24H.timeinfo', 'MedSparse.Bf24H.timevalues', 'MedSparse.Af2H.timestep', 'MedSparse.Af2H.input_ids', 'MedSparse.Af2H.input_wgts', 'MedSparse.Af2H.timeinfo', 'MedSparse.Af2H.timevalues', 'EduSparse.Bf24H.timestep', 'EduSparse.Bf24H.input_ids', 'EduSparse.Bf24H.input_wgts', 'EduSparse.Bf24H.timeinfo', 'EduSparse.Bf24H.timevalues', 'EduSparse.Af2H.timestep', 'EduSparse.Af2H.input_ids', 'EduSparse.Af2H.input_wgts', 'EduSparse.Af2H.timeinfo', 'EduSparse.Af2H.timevalues', 'DietSparse.Bf24H.timestep', 'DietSparse.Bf24H.input_ids', 'DietSparse.Bf24H.input_wgts', 'DietSparse.Bf24H.timeinfo', 'DietSparse.Bf24H.timevalues', 'DietSparse.Af2H.timestep', 'DietSparse.Af2H.input_ids', 'DietSparse.Af2H.input_wgts', 'DietSparse.Af2H.timeinfo', 'DietSparse.Af2H.timevalues', 'ActivitySparse.Bf24H.timestep', 'ActivitySparse.Bf24H.input_ids', 'ActivitySparse.Bf24H.input_wgts', 'ActivitySparse.Bf24H.timeinfo', 'ActivitySparse.Bf24H.timevalues', 'ActivitySparse.Af2H.timestep', 'ActivitySparse.Af2H.input_ids', 'ActivitySparse.Af2H.input_wgts', 'ActivitySparse.Af2H.timeinfo', 'ActivitySparse.Af2H.timevalues', 'LabVitalSparse.Bf24H.timestep', 'LabVitalSparse.Bf24H.input_ids', 'LabVitalSparse.Bf24H.input_wgts', 'LabVitalSparse.Bf24H.timeinfo', 'LabVitalSparse.Bf24H.timevalues', 'LabVitalSparse.Af2H.timestep', 'LabVitalSparse.Af2H.input_ids', 'LabVitalSparse.Af2H.input_wgts', 'LabVitalSparse.Af2H.timeinfo', 'LabVitalSparse.Af2H.timevalues'],\n",
       "    num_rows: 75\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fn_entry_method_for_finaldata(dataset, cf_to_CFVocab, EntryArgs)\n",
    "dataset = results['dataset']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be643840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[115, 115, 114,  ..., 158, 154, 149],\n",
       "         [111, 110, 109,  ..., 122, 122, 123],\n",
       "         [ 89,  89,  90,  ...,  94,  94,  94],\n",
       "         ...,\n",
       "         [192, 198, 200,  ..., 138, 133, 126],\n",
       "         [192, 186, 180,  ..., 146, 142, 137],\n",
       "         [203, 203, 204,  ..., 228, 231, 234]]),\n",
       " 'labels': tensor([[145, 140, 136, 133, 131, 128, 126, 125, 125, 127, 129, 130, 131, 131,\n",
       "          131, 130, 129, 129, 128, 128, 128, 129, 129, 128],\n",
       "         [124, 125, 127, 128, 129, 129, 129, 129, 129, 129, 129, 126, 125, 123,\n",
       "          123, 122, 123, 124, 124, 123, 121, 120, 119, 118],\n",
       "         [ 93,  93,  94,  94,  93,  93,  93,  94,  94,  93,  93,  93,  94,  96,\n",
       "           96,  97,  97,  97,  95,  94,  92,  92,  92,  93],\n",
       "         [196, 195, 195, 195, 193, 184, 169, 149, 129, 114, 110, 110, 112, 117,\n",
       "          132, 145, 153, 151, 147, 143, 141, 145, 148, 150],\n",
       "         [200, 199, 199, 199, 198, 194, 191, 191, 190, 189, 187, 191, 196, 200,\n",
       "          199, 196, 194, 193, 191, 190, 189, 188, 187, 185],\n",
       "         [121, 118, 118, 125, 132, 137, 137, 138, 142, 145, 144, 141, 138, 138,\n",
       "          140, 143, 144, 145, 145, 144, 142, 139, 137, 136],\n",
       "         [133, 130, 131, 131, 129, 125, 122, 121, 121, 122, 123, 122, 120, 117,\n",
       "          114, 110, 106, 104, 104, 106, 105, 102,  99,  96],\n",
       "         [239, 243, 248, 252, 255, 257, 259, 263, 259, 251, 242, 241, 244, 244,\n",
       "          242, 233, 230, 225, 224, 217, 213, 211, 212, 214]]),\n",
       " 'total_field_info': {'Field_Time': {'input_ids': tensor([[[ 12,  40,  79,  80, 104, 164],\n",
       "            [ 12,  40,  79,  80, 109, 164],\n",
       "            [ 12,  40,  79,  80, 114, 164],\n",
       "            ...,\n",
       "            [ 12,  41,  73,  81, 154, 164],\n",
       "            [ 12,  41,  73,  81, 159, 164],\n",
       "            [ 12,  41,  73,  82, 104, 164]],\n",
       "   \n",
       "           [[ 13,  42,  77,  80, 104, 164],\n",
       "            [ 13,  42,  77,  80, 109, 164],\n",
       "            [ 13,  42,  77,  80, 114, 164],\n",
       "            ...,\n",
       "            [ 13,  42,  78,  81, 154, 164],\n",
       "            [ 13,  42,  78,  81, 159, 164],\n",
       "            [ 13,  42,  78,  82, 104, 164]],\n",
       "   \n",
       "           [[ 15,  52,  79,  80, 104, 164],\n",
       "            [ 15,  52,  79,  80, 109, 164],\n",
       "            [ 15,  52,  79,  80, 114, 164],\n",
       "            ...,\n",
       "            [ 15,  53,  73,  81, 154, 164],\n",
       "            [ 15,  53,  73,  81, 159, 164],\n",
       "            [ 15,  53,  73,  82, 104, 164]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 16,  58,  75,  80, 104, 164],\n",
       "            [ 16,  58,  75,  80, 109, 164],\n",
       "            [ 16,  58,  75,  80, 114, 164],\n",
       "            ...,\n",
       "            [ 16,  58,  76,  81, 154, 164],\n",
       "            [ 16,  58,  76,  81, 159, 164],\n",
       "            [ 16,  58,  76,  82, 104, 164]],\n",
       "   \n",
       "           [[ 17,  61,  76,  80, 104, 164],\n",
       "            [ 17,  61,  76,  80, 109, 164],\n",
       "            [ 17,  61,  76,  80, 114, 164],\n",
       "            ...,\n",
       "            [ 17,  61,  77,  81, 154, 164],\n",
       "            [ 17,  61,  77,  81, 159, 164],\n",
       "            [ 17,  61,  77,  82, 104, 164]],\n",
       "   \n",
       "           [[ 18,  63,  76,  80, 104, 164],\n",
       "            [ 18,  63,  76,  80, 109, 164],\n",
       "            [ 18,  63,  76,  80, 114, 164],\n",
       "            ...,\n",
       "            [ 18,  63,  77,  81, 154, 164],\n",
       "            [ 18,  63,  77,  81, 159, 164],\n",
       "            [ 18,  63,  77,  82, 104, 164]]]),\n",
       "   'timestep_ids': tensor([[  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           ...,\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316]])},\n",
       "  'Field_Med': {'input_ids': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]]]),\n",
       "   'input_wgts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "   'timestep_ids': tensor([[  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           ...,\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316]])},\n",
       "  'Field_Edu': {'input_ids': tensor([[[1],\n",
       "            [1],\n",
       "            [1],\n",
       "            ...,\n",
       "            [1],\n",
       "            [1],\n",
       "            [1]],\n",
       "   \n",
       "           [[1],\n",
       "            [1],\n",
       "            [1],\n",
       "            ...,\n",
       "            [1],\n",
       "            [1],\n",
       "            [1]],\n",
       "   \n",
       "           [[1],\n",
       "            [1],\n",
       "            [1],\n",
       "            ...,\n",
       "            [1],\n",
       "            [1],\n",
       "            [1]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1],\n",
       "            [1],\n",
       "            [1],\n",
       "            ...,\n",
       "            [1],\n",
       "            [1],\n",
       "            [1]],\n",
       "   \n",
       "           [[1],\n",
       "            [1],\n",
       "            [1],\n",
       "            ...,\n",
       "            [1],\n",
       "            [1],\n",
       "            [1]],\n",
       "   \n",
       "           [[1],\n",
       "            [1],\n",
       "            [1],\n",
       "            ...,\n",
       "            [1],\n",
       "            [1],\n",
       "            [1]]]),\n",
       "   'input_wgts': tensor([[[0.],\n",
       "            [1.],\n",
       "            [1.],\n",
       "            ...,\n",
       "            [1.],\n",
       "            [1.],\n",
       "            [1.]],\n",
       "   \n",
       "           [[0.],\n",
       "            [1.],\n",
       "            [1.],\n",
       "            ...,\n",
       "            [1.],\n",
       "            [1.],\n",
       "            [1.]],\n",
       "   \n",
       "           [[0.],\n",
       "            [1.],\n",
       "            [1.],\n",
       "            ...,\n",
       "            [1.],\n",
       "            [1.],\n",
       "            [1.]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[0.],\n",
       "            [1.],\n",
       "            [1.],\n",
       "            ...,\n",
       "            [1.],\n",
       "            [1.],\n",
       "            [1.]],\n",
       "   \n",
       "           [[0.],\n",
       "            [1.],\n",
       "            [1.],\n",
       "            ...,\n",
       "            [1.],\n",
       "            [1.],\n",
       "            [1.]],\n",
       "   \n",
       "           [[0.],\n",
       "            [1.],\n",
       "            [1.],\n",
       "            ...,\n",
       "            [1.],\n",
       "            [1.],\n",
       "            [1.]]]),\n",
       "   'timestep_ids': tensor([[  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           ...,\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316]])},\n",
       "  'Field_Diet': {'input_ids': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]]]),\n",
       "   'input_wgts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "   'timestep_ids': tensor([[  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           ...,\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316]])},\n",
       "  'Field_Activity': {'input_ids': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]],\n",
       "   \n",
       "           [[1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0],\n",
       "            [1, 0, 0,  ..., 0, 0, 0]]]),\n",
       "   'input_wgts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "   \n",
       "           [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [1., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "   'timestep_ids': tensor([[  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           ...,\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316]])},\n",
       "  'Field_Lab': {'input_ids': tensor([[[1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            ...,\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0]],\n",
       "   \n",
       "           [[1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            ...,\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0]],\n",
       "   \n",
       "           [[1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            ...,\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            ...,\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0]],\n",
       "   \n",
       "           [[1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            ...,\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0]],\n",
       "   \n",
       "           [[1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            ...,\n",
       "            [1, 0],\n",
       "            [1, 0],\n",
       "            [1, 0]]]),\n",
       "   'input_wgts': tensor([[[0., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            ...,\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.]],\n",
       "   \n",
       "           [[0., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            ...,\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.]],\n",
       "   \n",
       "           [[0., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            ...,\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[0., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            ...,\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.]],\n",
       "   \n",
       "           [[0., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            ...,\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.]],\n",
       "   \n",
       "           [[0., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            ...,\n",
       "            [1., 0.],\n",
       "            [1., 0.],\n",
       "            [1., 0.]]]),\n",
       "   'timestep_ids': tensor([[  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           ...,\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316],\n",
       "           [  4,   5,   6,  ..., 314, 315, 316]])}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = dataset[:8]\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2d5567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 289)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_tfm['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9a50fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 24)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_tfm['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bc1c32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\n",
      "input_ids (4, 313, 6)\n",
      "timestep_ids (4, 313)\n",
      "Med\n",
      "input_ids (4, 313, 136)\n",
      "input_wgts (4, 313, 136)\n",
      "timestep_ids (4, 313)\n",
      "Edu\n",
      "input_ids (4, 313, 1)\n",
      "input_wgts (4, 313, 1)\n",
      "timestep_ids (4, 313)\n",
      "Diet\n",
      "input_ids (4, 313, 122)\n",
      "input_wgts (4, 313, 122)\n",
      "timestep_ids (4, 313)\n",
      "Activity\n",
      "input_ids (4, 313, 7)\n",
      "input_wgts (4, 313, 7)\n",
      "timestep_ids (4, 313)\n",
      "Lab\n",
      "input_ids (4, 313, 1)\n",
      "input_wgts (4, 313, 1)\n",
      "timestep_ids (4, 313)\n"
     ]
    }
   ],
   "source": [
    "fields = EntryArgs['MEDAL_Fields']\n",
    "# fields\n",
    "\n",
    "for field in fields:\n",
    "    print(field)\n",
    "    for k, v in examples_tfm['total_field_info'][f'Field_{field}'].items():\n",
    "        print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112787c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a4873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cd522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a06f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
