{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c938bf1",
   "metadata": {},
   "source": [
    "# Space\n",
    "\n",
    "\n",
    "version: 2024-02-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c872edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Shared drives\\CDHAI-WellDoc\\2024-WellDocTest-SPACE\\_WellDoc-RFT-WorkSpace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd \n",
    "from IPython.display import display, HTML\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import PROJECT, TaskName, SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_RFT'], 'config_recfldtkn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aca990",
   "metadata": {},
   "source": [
    "# [Part 1] Load dfHumanRecAttr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817dae8",
   "metadata": {},
   "source": [
    "## [Step 1]** Create FldTknName\n",
    "\n",
    "Motivation: To provide a flexible way to handle different types of configuration files or data records\n",
    "\n",
    "Aim: FldTknName is set to the name of a file ('Food-NutriN2CTkn' in this case); FldType is set to 'N2C' in this case.\n",
    "\n",
    "Input:\n",
    "\n",
    "Output:FldTknName and FldType\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red;\">Instruction:</span>\n",
    "1. change 'P-DemoCateTkn', in this example: P is rec name and DemoCateTkn is a specific tkn name\n",
    "2. change FldType. In general, we have a few different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ff3b00-c0db-4944-8fb3-01e95be33c79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightU\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "FldTknName = 'WeightU-N2CTkn' # <-------- select your yaml file name\n",
    "FldType = 'N2C'\n",
    "###########################\n",
    "\n",
    "FLD_TYPE_LIST = ['Cate', 'N2C', 'Nume', 'External']\n",
    "assert FldType in FLD_TYPE_LIST\n",
    "RecName = FldTknName.split('-')[0]\n",
    "print(RecName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e52ea",
   "metadata": {},
   "source": [
    "## [Step 2] Open  Rec yaml file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81f8979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:13,566:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn\\Record\\WeightU.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "../pipeline\\config_recfldtkn\\Record\\WeightU.yaml <a href=\"g:\\Shared drives\\CDHAI-WellDoc\\2024-WellDocTest-SPACE\\_WellDoc-RFT-WorkSpace\\../pipeline\\config_recfldtkn\\Record\\WeightU.yaml\" target=\"_blank\">Open File</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recfldtkn.configfn import load_cohort_args, load_record_args, load_fldtkn_args\n",
    "\n",
    "# step 1: create the FldTkn yaml file in recfldtkn_config_path\n",
    "cohort_args = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "record_args = load_record_args(RecName, cohort_args)\n",
    "fldtkn_args = load_fldtkn_args(RecName, FldTknName, cohort_args)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = record_args['yaml_file_path']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6de5f",
   "metadata": {},
   "source": [
    "## [Step 3]**: Add FldTknInfo to Record Yaml\n",
    "\n",
    "``` yaml\n",
    "FldTknInfo:\n",
    "  # <---- uodated information >\n",
    "  P-DemoCateTkn:  # RecName-FldTkn \n",
    "    value_cols:   # value columns\n",
    "      - Gender\n",
    "      - DiseaseType\n",
    "      - MRSegmentID\n",
    "  # <--------------------->\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba03a5",
   "metadata": {},
   "source": [
    "## [Step 4] Load FldTkn Args (from Record yaml's FldTkn part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6529980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:13,867:(config.py@58 datasets)]: PyTorch version 2.1.2+cu121 available.\n",
      "[INFO:2024-04-19 13:25:14,140:(configfn.py@116 recfldtkn.configfn)]: file_path in load_fldtkn_args: ../pipeline\\config_recfldtkn\\Record\\WeightU.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Weight']\n",
      "['PID', 'WeightUID', 'DT_s', 'Weight']\n"
     ]
    }
   ],
   "source": [
    "from recfldtkn.loadtools import load_ds_rec_and_info\n",
    "# load fldtkn_args\n",
    "fldtkn_args = load_fldtkn_args(RecName, FldTknName, cohort_args)\n",
    "fldtkn_args['attr_cols']\n",
    "\n",
    "# load dfHumanRecAttr\n",
    "value_cols = fldtkn_args['value_cols']\n",
    "attr_cols  = fldtkn_args['attr_cols'] # record_args['RecIDChain'] + value_cols\n",
    "\n",
    "print(value_cols)\n",
    "print(attr_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9c83b",
   "metadata": {},
   "source": [
    "## [Step 5] Prepare dfHumanRecAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be11acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28171, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>WeightUID</th>\n",
       "      <th>DT_s</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-0</td>\n",
       "      <td>2018-06-25 16:43:50</td>\n",
       "      <td>209.439149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-1</td>\n",
       "      <td>2018-08-16 06:51:00</td>\n",
       "      <td>207.234526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-2</td>\n",
       "      <td>2018-09-04 07:34:00</td>\n",
       "      <td>207.234526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-3</td>\n",
       "      <td>2018-12-12 15:06:00</td>\n",
       "      <td>208.998225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-4</td>\n",
       "      <td>2018-12-13 14:54:00</td>\n",
       "      <td>209.439149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PID  WeightUID                DT_s      Weight\n",
       "0  1000001  1000001-0 2018-06-25 16:43:50  209.439149\n",
       "1  1000001  1000001-1 2018-08-16 06:51:00  207.234526\n",
       "2  1000001  1000001-2 2018-09-04 07:34:00  207.234526\n",
       "3  1000001  1000001-3 2018-12-12 15:06:00  208.998225\n",
       "4  1000001  1000001-4 2018-12-13 14:54:00  209.439149"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "cohort_label_list = [1]\n",
    "############################\n",
    "\n",
    "\n",
    "dsHumanRecAttr, _ = load_ds_rec_and_info(RecName, cohort_args, cohort_label_list)\n",
    "dfHumanRecAttr = dsHumanRecAttr.select_columns(attr_cols).to_pandas()\n",
    "print(dfHumanRecAttr.shape)\n",
    "del dsHumanRecAttr\n",
    "\n",
    "\n",
    "if len(dfHumanRecAttr) > 100000:\n",
    "    dfHumanRecAttr = dfHumanRecAttr.head(100000)\n",
    "    \n",
    "dfHumanRecAttr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5907a",
   "metadata": {},
   "source": [
    "# [Part 2]: Design $\\phi$ pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06bac8",
   "metadata": {},
   "source": [
    "## [Step 1]* [Pre-defined Token Vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PID', 'WeightUID', 'DT_s', 'Weight']\n",
      "['Weight']\n",
      "FldType: N2C\n",
      "         Weight\n",
      "count  28171.00\n",
      "mean     208.19\n",
      "std       44.73\n",
      "min        1.00\n",
      "25%      174.52\n",
      "50%      209.80\n",
      "75%      236.60\n",
      "max      555.00\n"
     ]
    }
   ],
   "source": [
    "print(fldtkn_args['attr_cols'])\n",
    "print(fldtkn_args['value_cols'])\n",
    "print('FldType:', FldType)\n",
    "\n",
    "column_to_top_values = {}\n",
    "item_to_configs = {}\n",
    "\n",
    "if FldType == 'Cate':\n",
    "    ############################### for Cate Tkn only\n",
    "    column_to_top_values = {}\n",
    "    TOP_NUM = 30\n",
    "    cols = fldtkn_args['value_cols']\n",
    "    for col in cols:\n",
    "        top_tkn = list(dfHumanRecAttr[col].value_counts().iloc[:TOP_NUM].index)\n",
    "        print(col, len(top_tkn), top_tkn)\n",
    "        column_to_top_values[col] = top_tkn # tolist()\n",
    "    ###############################\n",
    "        \n",
    "elif FldType == 'N2C':\n",
    "    ############################### for N2C Tkn only, you need to modify this part. \n",
    "    cols = fldtkn_args['value_cols']\n",
    "    descp = dfHumanRecAttr[cols].astype(float).describe().round(2)#.to_dict()\n",
    "    print(descp)\n",
    "    item_to_configs = {\n",
    "       'Weight': {'Max': 300, 'Min': 100, 'INTERVAL': 10}, # <--- you need to modify this part\n",
    "    }\n",
    "    ###############################\n",
    "\n",
    "elif FldType == 'External':\n",
    "    df_db = fldtkn_args['external_source']\n",
    "    display(HTML(df_db.head().to_html()))\n",
    "\n",
    "else:\n",
    "    assert FldType in FLD_TYPE_LIST\n",
    "    \n",
    "fldtkn_args[f'column_to_top_values'] = column_to_top_values\n",
    "fldtkn_args['item_to_configs'] = item_to_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72185e19",
   "metadata": {},
   "source": [
    "## [Step 2]* Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9849ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show tokenizer_fn result\n",
      "{'PID': 1000001, 'WeightUID': '1000001-0', 'DT_s': Timestamp('2018-06-25 16:43:50'), 'Weight': 209.439149075634}\n",
      "{'tkn': ['Weight:200~210', 'Weight:200~210Level'], 'wgt': [1, 0.9439149075633992]}\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "################################## You might need to change it a bit. \n",
    "def tokenizer_fn(rec, fldtkn_args):\n",
    "    d = {}\n",
    "\n",
    "    # #----------- Cate\n",
    "    # column_to_top_values = fldtkn_args[f'column_to_top_values']\n",
    "    # for key in column_to_top_values:\n",
    "    #     top_values = column_to_top_values[key]\n",
    "    #     value = rec.get(key, 'unk')\n",
    "    #     if value not in top_values and value != 'unk': value = 'minor'\n",
    "    #     key_value = f\"{key}_{value}\"  # Concatenate key and value\n",
    "    #     d[key_value] = 1\n",
    "\n",
    "    #------------ N2C with interval and intervel level. \n",
    "    item_to_configs = fldtkn_args['item_to_configs']\n",
    "    for item, configs in item_to_configs.items():\n",
    "        Max = configs['Max']\n",
    "        Min = configs['Min']\n",
    "        INTERVAL = configs['INTERVAL']\n",
    "        if pd.isnull(rec.get(item, None)):\n",
    "            d[f\"{item}:None\"] = 1\n",
    "        elif float(rec[item]) > Max:\n",
    "            d[ f\"{item}:Above{Max}\"] = 1\n",
    "        elif float(rec[item]) < Min:\n",
    "            d[ f\"{item}:Below{Min}\"] = 1\n",
    "        else:\n",
    "            lower_bound = int((float(rec[item]) // INTERVAL) * INTERVAL)\n",
    "            upper_bound = int(lower_bound + INTERVAL)\n",
    "            # Calculate the proportion of value within the interval\n",
    "            proportion = (float(rec[item]) - lower_bound) / INTERVAL\n",
    "            # Construct the keys\n",
    "            key1 = f\"{item}:{lower_bound}~{upper_bound}\"\n",
    "            key2 = f\"{key1}Level\"\n",
    "            # Add them to the dictionary with appropriate weights\n",
    "            d[key1] = 1\n",
    "            d[key2] = proportion\n",
    "\n",
    "    # #------------ Nume\n",
    "    # for col in fldtkn_args['value_cols']:\n",
    "    #     x = rec[col]\n",
    "    #     if pd.isnull(x):\n",
    "    #         d[f'{col}_None'] = 1\n",
    "    #     else:\n",
    "    #         d[col] = float(x)\n",
    "\n",
    "    # #------------ ExternalSource: zip3 as an example. This is case by case. \n",
    "    ##############################################################\n",
    "    ##     this part can be moved to big Phi in the future.     ##\n",
    "    ##############################################################\n",
    "    # df_db = fldtkn_args['external_source']\n",
    "    # try:\n",
    "    #     external_id = str(int(rec['patient_zipcode_3']))\n",
    "    # except:\n",
    "    #     external_id = str(rec['patient_zipcode_3'])\n",
    "\n",
    "    # if external_id not in df_db['Zip3'].to_list():\n",
    "    #     return {'tkn': ['zip3-None'], 'wgt':[1]}\n",
    "    # row = df_db[df_db['Zip3'] == external_id].iloc[0].to_dict()\n",
    "    # tkn_col = [i for i in df_db.columns if 'tkn' in i][0]\n",
    "    # wgt_col = [i for i in df_db.columns if 'wgt' in i][0]\n",
    "    # d = dict(zip(row[tkn_col], row[wgt_col]))\n",
    "\n",
    "\n",
    "    tkn = list(d.keys())\n",
    "    wgt = list(d.values())\n",
    "    output = {'tkn': tkn, 'wgt': wgt}\n",
    "    return output\n",
    "##################################\n",
    "\n",
    "tokenizer_fn.fn_string = inspect.getsource(tokenizer_fn)\n",
    "\n",
    "print('show tokenizer_fn result')\n",
    "rec = dfHumanRecAttr.iloc[0]\n",
    "print(rec.to_dict())\n",
    "print(tokenizer_fn(rec, fldtkn_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709344e5",
   "metadata": {},
   "source": [
    "## [Step 3]* Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245f2a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show idx2tkn for FldType: N2C\n",
      "45\n",
      "['Weight:100~110', 'Weight:100~110Level', 'Weight:110~120', 'Weight:110~120Level', 'Weight:120~130', 'Weight:120~130Level', 'Weight:130~140', 'Weight:130~140Level', 'Weight:140~150', 'Weight:140~150Level']\n",
      "46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['unk',\n",
       " 'Weight:100~110',\n",
       " 'Weight:100~110Level',\n",
       " 'Weight:110~120',\n",
       " 'Weight:110~120Level',\n",
       " 'Weight:120~130',\n",
       " 'Weight:120~130Level',\n",
       " 'Weight:130~140',\n",
       " 'Weight:130~140Level',\n",
       " 'Weight:140~150',\n",
       " 'Weight:140~150Level',\n",
       " 'Weight:150~160',\n",
       " 'Weight:150~160Level',\n",
       " 'Weight:160~170',\n",
       " 'Weight:160~170Level',\n",
       " 'Weight:170~180',\n",
       " 'Weight:170~180Level',\n",
       " 'Weight:180~190',\n",
       " 'Weight:180~190Level',\n",
       " 'Weight:190~200',\n",
       " 'Weight:190~200Level',\n",
       " 'Weight:200~210',\n",
       " 'Weight:200~210Level',\n",
       " 'Weight:210~220',\n",
       " 'Weight:210~220Level',\n",
       " 'Weight:220~230',\n",
       " 'Weight:220~230Level',\n",
       " 'Weight:230~240',\n",
       " 'Weight:230~240Level',\n",
       " 'Weight:240~250',\n",
       " 'Weight:240~250Level',\n",
       " 'Weight:250~260',\n",
       " 'Weight:250~260Level',\n",
       " 'Weight:260~270',\n",
       " 'Weight:260~270Level',\n",
       " 'Weight:270~280',\n",
       " 'Weight:270~280Level',\n",
       " 'Weight:280~290',\n",
       " 'Weight:280~290Level',\n",
       " 'Weight:290~300',\n",
       " 'Weight:290~300Level',\n",
       " 'Weight:300~310',\n",
       " 'Weight:300~310Level',\n",
       " 'Weight:Above300',\n",
       " 'Weight:Below100',\n",
       " 'Weight:None']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def sort_fn(s):\n",
    "    try:\n",
    "        return int(s.split(':')[-1].split('~')[0])\n",
    "    except:\n",
    "        return float('inf')\n",
    "    \n",
    "print('show idx2tkn for FldType:', FldType )\n",
    "if FldType == 'Cate':\n",
    "    ############################################## Cate Tkn only\n",
    "    idx2tkn = []\n",
    "    for col, values in column_to_top_values.items():\n",
    "        idx2tkn = idx2tkn + [f'{col}_unk', f'{col}_minor']\n",
    "        for val in values:\n",
    "            idx2tkn.append(f\"{col}_{val}\")\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'N2C':\n",
    "    ############################################## for N2C only\n",
    "    Min, Max = -10, 3000 # <---- keep this as default. don't change it.\n",
    "    df_simu = pd.DataFrame({\n",
    "        col: [None] + list(range(Min, Max )) for col in item_to_configs.keys()\n",
    "    })\n",
    "    df_sim = pd.DataFrame(df_simu.apply(lambda rec: tokenizer_fn(rec, fldtkn_args), axis = 1).to_list())\n",
    "    idx2tkn = sorted(list(set(itertools.chain(*df_sim['tkn'].to_list()))))\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'Nume':\n",
    "    ############################################## for Nume\n",
    "    idx2tkn = fldtkn_args['value_cols'] + [f'{col}_None' for col in fldtkn_args['value_cols']]\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'External':\n",
    "    none_tkn = 'zip3-None' # <--- you need to change this.\n",
    "    tkn_col = [i for i in df_db.columns if 'tkn' in i][0]\n",
    "    idx2tkn = [none_tkn] +sorted(list(set(itertools.chain(*fldtkn_args['external_source'][tkn_col].to_list()))))\n",
    "    print(len(idx2tkn[:10]))\n",
    "\n",
    "else:\n",
    "    assert FldType in FLD_TYPE_LIST\n",
    "\n",
    "\n",
    "idx2tkn = sorted(idx2tkn, key = sort_fn)\n",
    "idx2tkn = ['unk'] + idx2tkn\n",
    "print(len(idx2tkn))\n",
    "idx2tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d51e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx2tkn    [unk, Weight:100~110, Weight:100~110Level, Wei...\n",
       "tkn2idx    {'unk': 0, 'Weight:100~110': 1, 'Weight:100~11...\n",
       "tkn2fld    {'unk': 'WeightU-N2CTkn', 'Weight:100~110': 'W...\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recfldtkn.pipeline_record import get_and_save_vocab_from_idx2tkn\n",
    "Vocab = get_and_save_vocab_from_idx2tkn(idx2tkn, **fldtkn_args)\n",
    "Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6eb0",
   "metadata": {},
   "source": [
    "# Part 4: Application\n",
    "\n",
    "## [Step 1] Save PyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063a40da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "../pipeline/fn_fldtkn/WeightU_N2CTkn.py <a href=\"g:\\Shared drives\\CDHAI-WellDoc\\2024-WellDocTest-SPACE\\_WellDoc-RFT-WorkSpace\\../pipeline/fn_fldtkn/WeightU_N2CTkn.py\" target=\"_blank\">Open File</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recfldtkn.loadtools import convert_variables_to_pystirng, load_module_variables\n",
    "\n",
    "prefix = ['import pandas as pd', 'import numpy as np']\n",
    "iterative_variables = [column_to_top_values, item_to_configs, idx2tkn] # <-- don't forget to update this.\n",
    "fn_variables = [tokenizer_fn]\n",
    "pycode = convert_variables_to_pystirng(iterative_variables = iterative_variables, fn_variables = fn_variables, prefix = prefix)\n",
    "RecName = record_args['RecName']\n",
    "pypath = fldtkn_args['pypath']\n",
    "# print(pypath)\n",
    "with open(pypath, 'w') as file: file.write(pycode)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = fldtkn_args['pypath']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cabf8d",
   "metadata": {},
   "source": [
    "\n",
    "## [Step 2] Load PyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74e631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_module_variables(pypath)\n",
    "\n",
    "# tokenizer_fn\n",
    "tokenizer_fn = module.MetaDict['tokenizer_fn']\n",
    "\n",
    "# idx2tkn\n",
    "idx2tkn = module.MetaDict['idx2tkn']\n",
    "\n",
    "if 'column_to_top_values' in module.MetaDict:\n",
    "    fldtkn_args['column_to_top_values'] = module.MetaDict['column_to_top_values']\n",
    "if 'item_to_configs' in module.MetaDict:\n",
    "    fldtkn_args['item_to_configs'] = module.MetaDict['item_to_configs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bf04a",
   "metadata": {},
   "source": [
    "## [Step 3] Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc86bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 2024-04-19 13:25:15.004504\n",
      "e 2024-04-19 13:25:15.304026\n",
      "Total memory usage: 0.86 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>WeightUID</th>\n",
       "      <th>WeightU-N2CTkn_tknidx</th>\n",
       "      <th>WeightU-N2CTkn_wgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-0</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[1, 0.9439149075633992]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-1</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[1, 0.7234526453785008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-2</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[1, 0.7234526453785008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-3</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[1, 0.8998224551264002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-4</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[1, 0.9439149075633992]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PID  WeightUID WeightU-N2CTkn_tknidx       WeightU-N2CTkn_wgt\n",
       "0  1000001  1000001-0              [21, 22]  [1, 0.9439149075633992]\n",
       "1  1000001  1000001-1              [21, 22]  [1, 0.7234526453785008]\n",
       "2  1000001  1000001-2              [21, 22]  [1, 0.7234526453785008]\n",
       "3  1000001  1000001-3              [21, 22]  [1, 0.8998224551264002]\n",
       "4  1000001  1000001-4              [21, 22]  [1, 0.9439149075633992]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recfldtkn.pipeline_record import tokenizer_dfHumanRecAttr\n",
    "from datetime import datetime\n",
    "\n",
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args,\n",
    "                                 use_tknidx = True)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e5139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 2024-04-19 13:25:15.336731\n",
      "e 2024-04-19 13:25:15.621844\n",
      "Total memory usage: 0.86 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>WeightUID</th>\n",
       "      <th>WeightU-N2CTkn_tkn</th>\n",
       "      <th>WeightU-N2CTkn_wgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-0</td>\n",
       "      <td>[Weight:200~210, Weight:200~210Level]</td>\n",
       "      <td>[1, 0.9439149075633992]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-1</td>\n",
       "      <td>[Weight:200~210, Weight:200~210Level]</td>\n",
       "      <td>[1, 0.7234526453785008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-2</td>\n",
       "      <td>[Weight:200~210, Weight:200~210Level]</td>\n",
       "      <td>[1, 0.7234526453785008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-3</td>\n",
       "      <td>[Weight:200~210, Weight:200~210Level]</td>\n",
       "      <td>[1, 0.8998224551264002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001-4</td>\n",
       "      <td>[Weight:200~210, Weight:200~210Level]</td>\n",
       "      <td>[1, 0.9439149075633992]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PID  WeightUID                     WeightU-N2CTkn_tkn  \\\n",
       "0  1000001  1000001-0  [Weight:200~210, Weight:200~210Level]   \n",
       "1  1000001  1000001-1  [Weight:200~210, Weight:200~210Level]   \n",
       "2  1000001  1000001-2  [Weight:200~210, Weight:200~210Level]   \n",
       "3  1000001  1000001-3  [Weight:200~210, Weight:200~210Level]   \n",
       "4  1000001  1000001-4  [Weight:200~210, Weight:200~210Level]   \n",
       "\n",
       "        WeightU-N2CTkn_wgt  \n",
       "0  [1, 0.9439149075633992]  \n",
       "1  [1, 0.7234526453785008]  \n",
       "2  [1, 0.7234526453785008]  \n",
       "3  [1, 0.8998224551264002]  \n",
       "4  [1, 0.9439149075633992]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args, \n",
    "                                 use_tknidx = False)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf1a92",
   "metadata": {},
   "source": [
    "# Save RFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8578ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:15,663:(3358717945.py@17 __main__)]: \n",
      "\n",
      "=================1-RawData2022_CGM=================\n",
      "\n",
      "[INFO:2024-04-19 13:25:15,664:(3358717945.py@21 __main__)]: ../_Data/1-Data_RFT\\1-RawData2022_CGM\\WeightU\n",
      "[INFO:2024-04-19 13:25:15,731:(3358717945.py@23 __main__)]: Dataset({\n",
      "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx'],\n",
      "    num_rows: 28171\n",
      "})\n",
      "[INFO:2024-04-19 13:25:15,732:(pipeline_record.py@477 recfldtkn.pipeline_record)]: load fldtkn pipeline from: ../pipeline/fn_fldtkn/WeightU_N2CTkn.py ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca4aec9704d49899f58892f54b4f711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/28171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:18,411:(pipeline_record.py@494 recfldtkn.pipeline_record)]: ds_rec.column_names: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'] ...\n",
      "[INFO:2024-04-19 13:25:18,412:(3358717945.py@33 __main__)]: Dataset({\n",
      "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'],\n",
      "    num_rows: 28171\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd32004c85f4766b180f171f508face",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/28171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:18,654:(3358717945.py@17 __main__)]: \n",
      "\n",
      "=================2-RawData2023_CVSTDCAug=================\n",
      "\n",
      "[INFO:2024-04-19 13:25:18,654:(3358717945.py@21 __main__)]: ../_Data/1-Data_RFT\\2-RawData2023_CVSTDCAug\\WeightU\n",
      "[INFO:2024-04-19 13:25:18,744:(3358717945.py@23 __main__)]: Dataset({\n",
      "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx'],\n",
      "    num_rows: 83107\n",
      "})\n",
      "[INFO:2024-04-19 13:25:18,744:(pipeline_record.py@477 recfldtkn.pipeline_record)]: load fldtkn pipeline from: ../pipeline/fn_fldtkn/WeightU_N2CTkn.py ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d02f2b3d49b4dbabdc214a5a555acfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/83107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:21,929:(pipeline_record.py@494 recfldtkn.pipeline_record)]: ds_rec.column_names: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'] ...\n",
      "[INFO:2024-04-19 13:25:21,930:(3358717945.py@33 __main__)]: Dataset({\n",
      "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'],\n",
      "    num_rows: 83107\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37269d566cfd46a19b716e47dc52af75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/83107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:22,410:(3358717945.py@17 __main__)]: \n",
      "\n",
      "=================3-RawData2023_CVSDeRxAug=================\n",
      "\n",
      "[INFO:2024-04-19 13:25:22,410:(3358717945.py@21 __main__)]: ../_Data/1-Data_RFT\\3-RawData2023_CVSDeRxAug\\WeightU\n",
      "[INFO:2024-04-19 13:25:22,481:(3358717945.py@23 __main__)]: Dataset({\n",
      "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx'],\n",
      "    num_rows: 5194\n",
      "})\n",
      "[INFO:2024-04-19 13:25:22,482:(pipeline_record.py@477 recfldtkn.pipeline_record)]: load fldtkn pipeline from: ../pipeline/fn_fldtkn/WeightU_N2CTkn.py ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dd653b611944e68d93ea3f53b0478b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2024-04-19 13:25:24,913:(pipeline_record.py@494 recfldtkn.pipeline_record)]: ds_rec.column_names: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'] ...\n",
      "[INFO:2024-04-19 13:25:24,913:(3358717945.py@33 __main__)]: Dataset({\n",
      "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'],\n",
      "    num_rows: 5194\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ab1c9e69db41fc9bcfbf9a34541600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['PID', 'PatientID', 'WeightUID', 'DT_r', 'DT_s', 'DT_tz', 'Weight', 'WeightU-NumeTkn_wgt', 'WeightU-NumeTkn_tknidx', 'WeightU-N2CTkn_wgt', 'WeightU-N2CTkn_tknidx'],\n",
       "    num_rows: 116472\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from recfldtkn.pipeline_record import pipeline_for_FldTkn\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "############################\n",
    "cohort_label_list = [1, 2, 3]\n",
    "############################\n",
    "\n",
    "\n",
    "cohort_label_to_cohort_name = {i.split('-')[0]:i.split('-')[1]  for i in os.listdir(SPACE['DATA_RFT']) if '-' in i}\n",
    "\n",
    "for cohort_label in cohort_label_list:\n",
    "    cohort_name = cohort_label_to_cohort_name[str(cohort_label)]\n",
    "    cohort_full_name = f'{cohort_label}-{cohort_name}'\n",
    "    logger.info(f'\\n\\n================={cohort_full_name}=================\\n')\n",
    "    \n",
    "    \n",
    "    data_folder = os.path.join(SPACE['DATA_RFT'], cohort_full_name,  RecName)\n",
    "    logger.info(data_folder)\n",
    "    ds_rec, _ = load_ds_rec_and_info(RecName, cohort_args, [cohort_label])\n",
    "    logger.info(ds_rec)\n",
    "    \n",
    "    fldtkn_args['Name'] = FldTknName\n",
    "    \n",
    "    if 'tkn' in ds_rec.column_names:\n",
    "        logger.info(ds_rec.column_names)\n",
    "        ds_rec = ds_rec.remove_columns('tkn')\n",
    "        \n",
    "    ds_rec = pipeline_for_FldTkn(ds_rec, fldtkn_args)\n",
    "    # ds_rec = ds_rec.map(lambda x: tokenizer_fn(x, fldtkn_args))\n",
    "    logger.info(ds_rec)\n",
    "    \n",
    "    # ds_rec.save_to_disk(data_folder + '_data')\n",
    "    # # save to another folder\n",
    "    ds_rec.save_to_disk(data_folder + '_data_tmp')\n",
    "    # ds_rec_info.save_to_disk(data_folder + '_info_tmp')\n",
    "    del ds_rec # , ds_rec_info\n",
    "    # shutil.rmtree(data_folder + '_data')\n",
    "    directory_to_remove = data_folder + '_data'\n",
    "    shutil.rmtree(directory_to_remove)\n",
    "    os.rename(data_folder + '_data_tmp', data_folder + '_data')\n",
    "    \n",
    "ds_rec, _ = load_ds_rec_and_info(RecName, cohort_args)\n",
    "ds_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b047e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
