{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c938bf1",
   "metadata": {},
   "source": [
    "# Space\n",
    "\n",
    "\n",
    "version: 2024-02-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c872edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xiruihan/Library/CloudStorage/GoogleDrive-rui.han.cdhai@gmail.com/Shared drives/CDHAI-WellDoc/2024-WellDocTest-SPACE/_RFT-WorkSpace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd \n",
    "from IPython.display import display, HTML\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import PROJECT, TaskName, SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_RFT'], 'config_recfldtkn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aca990",
   "metadata": {},
   "source": [
    "# [part 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817dae8",
   "metadata": {},
   "source": [
    "## [step 1] Load dfHumanRecAttr\n",
    "\n",
    "Motivation: \n",
    "\n",
    "Aim: \n",
    "\n",
    "Input:\n",
    "\n",
    "Output:\n",
    "\n",
    "Instruction: \n",
    "1. change FldTknName\n",
    "2. change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ff3b00-c0db-4944-8fb3-01e95be33c79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "FldTknName = 'Food-NutriN2CTkn'# <-------- select your yaml file name\n",
    "FldType = 'Cate'\n",
    "###########################\n",
    "\n",
    "FLD_TYPE_LIST = ['Cate', 'N2C', 'Nume', 'External']\n",
    "assert FldType in FLD_TYPE_LIST\n",
    "RecName = FldTknName.split('-')[0]\n",
    "print(RecName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81f8979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "../pipeline/config_recfldtkn/Record/RecName.yaml <a href=\"/Users/xiruihan/Library/CloudStorage/GoogleDrive-rui.han.cdhai@gmail.com/Shared drives/CDHAI-WellDoc/2024-WellDocTest-SPACE/_RFT-WorkSpace/../pipeline/config_recfldtkn/Record/RecName.yaml\" target=\"_blank\">Open File</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recfldtkn.configfn import load_cohort_args, load_record_args, load_fldtkn_args\n",
    "\n",
    "# step 1: create the FldTkn yaml file in recfldtkn_config_path\n",
    "cohort_args = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "record_args = load_record_args(RecName, cohort_args)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = record_args['yaml_file_path']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'shadow_RecTables_args' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecfldtkn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloadtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_ds_rec_and_info\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# load fldtkn_args\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m fldtkn_args \u001b[38;5;241m=\u001b[39m \u001b[43mload_fldtkn_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRecName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFldTknName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohort_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# load dfHumanRecAttr\u001b[39;00m\n\u001b[1;32m      6\u001b[0m value_cols \u001b[38;5;241m=\u001b[39m fldtkn_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_cols\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-rui.han.cdhai@gmail.com/Shared drives/CDHAI-WellDoc/2024-WellDocTest-SPACE/_RFT-WorkSpace/../pipeline/recfldtkn/configfn.py:105\u001b[0m, in \u001b[0;36mload_fldtkn_args\u001b[0;34m(RecName, FldTknName, cohort_args, recfldtkn_config_path)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# with open(file_path, 'r') as file: record_args = yaml.safe_load(file)\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m record_args \u001b[38;5;241m=\u001b[39m \u001b[43mload_record_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRecName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohort_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecfldtkn_config_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m fldtkn_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    108\u001b[0m fldtkn_args \u001b[38;5;241m=\u001b[39m record_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFldTknInfo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(FldTknName, fldtkn_args)\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-rui.han.cdhai@gmail.com/Shared drives/CDHAI-WellDoc/2024-WellDocTest-SPACE/_RFT-WorkSpace/../pipeline/recfldtkn/configfn.py:87\u001b[0m, in \u001b[0;36mload_record_args\u001b[0;34m(RecName, cohort_args, use_inference, recfldtkn_config_path)\u001b[0m\n\u001b[1;32m     85\u001b[0m CohortName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# print(shadow_CohortName)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m RecTables_args \u001b[38;5;241m=\u001b[39m \u001b[43mshadow_RecTables_args\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m RecTable, Table_args \u001b[38;5;129;01min\u001b[39;00m RecTables_args\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     89\u001b[0m     path \u001b[38;5;241m=\u001b[39m Table_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_data_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'shadow_RecTables_args' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from recfldtkn.loadtools import load_ds_rec_and_info\n",
    "# load fldtkn_args\n",
    "fldtkn_args = load_fldtkn_args(RecName, FldTknName, cohort_args)\n",
    "\n",
    "# load dfHumanRecAttr\n",
    "value_cols = fldtkn_args['value_cols']\n",
    "attr_cols  = fldtkn_args['attr_cols'] # record_args['RecIDChain'] + value_cols\n",
    "dsHumanRecAttr, _ = load_ds_rec_and_info(RecName, cohort_args)\n",
    "dfHumanRecAttr = dsHumanRecAttr.select_columns(attr_cols).to_pandas()\n",
    "print(dfHumanRecAttr.shape)\n",
    "dfHumanRecAttr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06bac8",
   "metadata": {},
   "source": [
    "# [Pre-defined Token Vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fldtkn_args['attr_cols'])\n",
    "print(fldtkn_args['value_cols'])\n",
    "print('FldType:', FldType)\n",
    "\n",
    "column_to_top_values = {}\n",
    "item_to_configs = {}\n",
    "\n",
    "if FldType == 'Cate':\n",
    "    ############################### for Cate Tkn only\n",
    "    column_to_top_values = {}\n",
    "    TOP_NUM = 30\n",
    "    cols = fldtkn_args['value_cols']\n",
    "    for col in cols:\n",
    "        top_tkn = list(dfHumanRecAttr[col].value_counts().iloc[:TOP_NUM].index)\n",
    "        print(col, len(top_tkn), top_tkn)\n",
    "        column_to_top_values[col] = top_tkn # tolist()\n",
    "    ###############################\n",
    "        \n",
    "elif FldType == 'N2C':\n",
    "    ############################### for N2C Tkn only, you need to modify this part. \n",
    "    cols = fldtkn_args['value_cols']\n",
    "    descp = dfHumanRecAttr[cols].astype(float).describe().round(2)#.to_dict()\n",
    "    print(descp)\n",
    "    item_to_configs = {\n",
    "        'XXX': {'Max': 600, 'Min': 1, 'INTERVAL': 1},\n",
    "    }\n",
    "    ###############################\n",
    "\n",
    "elif FldType == 'External':\n",
    "    df_db = fldtkn_args['external_source']\n",
    "    display(HTML(df_db.head().to_html()))\n",
    "\n",
    "else:\n",
    "    assert FldType in FLD_TYPE_LIST\n",
    "    \n",
    "fldtkn_args[f'column_to_top_values'] = column_to_top_values\n",
    "fldtkn_args['item_to_configs'] = item_to_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72185e19",
   "metadata": {},
   "source": [
    "# [Tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9849ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "################################## You might need to change it a bit. \n",
    "def tokenizer_fn(rec, fldtkn_args):\n",
    "    d = {}\n",
    "\n",
    "    # #----------- Cate\n",
    "    # column_to_top_values = fldtkn_args[f'column_to_top_values']\n",
    "    # for key in column_to_top_values:\n",
    "    #     top_values = column_to_top_values[key]\n",
    "    #     value = rec.get(key, 'unk')\n",
    "    #     if value not in top_values and value != 'unk': value = 'minor'\n",
    "    #     key_value = f\"{key}_{value}\"  # Concatenate key and value\n",
    "    #     d[key_value] = 1\n",
    "\n",
    "    # #------------ N2C with interval and intervel level. \n",
    "    # item_to_configs = fldtkn_args['item_to_configs']\n",
    "    # for item, configs in item_to_configs.items():\n",
    "    #     Max = configs['Max']\n",
    "    #     Min = configs['Min']\n",
    "    #     INTERVAL = configs['INTERVAL']\n",
    "    #     if pd.isnull(rec.get(item, None)):\n",
    "    #         d[f\"{item}:None\"] = 1\n",
    "    #     elif float(rec[item]) > Max:\n",
    "    #         d[ f\"{item}:Above{Max}\"] = 1\n",
    "    #     elif float(rec[item]) < Min:\n",
    "    #         d[ f\"{item}:Below{Min}\"] = 1\n",
    "    #     else:\n",
    "    #         lower_bound = int((float(rec[item]) // INTERVAL) * INTERVAL)\n",
    "    #         upper_bound = int(lower_bound + INTERVAL)\n",
    "    #         # Calculate the proportion of value within the interval\n",
    "    #         proportion = (float(rec[item]) - lower_bound) / INTERVAL\n",
    "    #         # Construct the keys\n",
    "    #         key1 = f\"{item}:{lower_bound}~{upper_bound}\"\n",
    "    #         key2 = f\"{key1}Level\"\n",
    "    #         # Add them to the dictionary with appropriate weights\n",
    "    #         d[key1] = 1\n",
    "    #         d[key2] = proportion\n",
    "\n",
    "    # #------------ Nume\n",
    "    # for col in fldtkn_args['value_cols']:\n",
    "    #     x = rec[col]\n",
    "    #     if pd.isnull(x):\n",
    "    #         d[f'{col}_None'] = 1\n",
    "    #     else:\n",
    "    #         d[col] = float(x)\n",
    "\n",
    "    # #------------ ExternalSource: zip3 as an example. This is case by case. \n",
    "    ##############################################################\n",
    "    ##     this part can be moved to big Phi in the future.     ##\n",
    "    ##############################################################\n",
    "    # df_db = fldtkn_args['external_source']\n",
    "    # try:\n",
    "    #     external_id = str(int(rec['patient_zipcode_3']))\n",
    "    # except:\n",
    "    #     external_id = str(rec['patient_zipcode_3'])\n",
    "\n",
    "    # if external_id not in df_db['Zip3'].to_list():\n",
    "    #     return {'tkn': ['zip3-None'], 'wgt':[1]}\n",
    "    # row = df_db[df_db['Zip3'] == external_id].iloc[0].to_dict()\n",
    "    # tkn_col = [i for i in df_db.columns if 'tkn' in i][0]\n",
    "    # wgt_col = [i for i in df_db.columns if 'wgt' in i][0]\n",
    "    # d = dict(zip(row[tkn_col], row[wgt_col]))\n",
    "\n",
    "\n",
    "    tkn = list(d.keys())\n",
    "    wgt = list(d.values())\n",
    "    output = {'tkn': tkn, 'wgt': wgt}\n",
    "    return output\n",
    "##################################\n",
    "\n",
    "tokenizer_fn.fn_string = inspect.getsource(tokenizer_fn)\n",
    "\n",
    "print('show tokenizer_fn result')\n",
    "rec = dfHumanRecAttr.iloc[0]\n",
    "print(rec.to_dict())\n",
    "print(tokenizer_fn(rec, fldtkn_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709344e5",
   "metadata": {},
   "source": [
    "# [Vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "print('show idx2tkn for FldType:', FldType )\n",
    "if FldType == 'Cate':\n",
    "    ############################################## Cate Tkn only\n",
    "    idx2tkn = []\n",
    "    for col, values in column_to_top_values.items():\n",
    "        idx2tkn = idx2tkn + [f'{col}_unk', f'{col}_minor']\n",
    "        for val in values:\n",
    "            idx2tkn.append(f\"{col}_{val}\")\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'N2C':\n",
    "    ############################################## for N2C only\n",
    "    Min, Max = -10, 3000 # <---- keep this as default. don't change it.\n",
    "    df_simu = pd.DataFrame({\n",
    "        col: [None] + list(range(Min, Max )) for col in item_to_configs.keys()\n",
    "    })\n",
    "    df_sim = pd.DataFrame(df_simu.apply(lambda rec: tokenizer_fn(rec, fldtkn_args), axis = 1).to_list())\n",
    "    idx2tkn = sorted(list(set(itertools.chain(*df_sim['tkn'].to_list()))))\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'Nume':\n",
    "    ############################################## for Nume\n",
    "    idx2tkn = fldtkn_args['value_cols'] + [f'{col}_None' for col in fldtkn_args['value_cols']]\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'External':\n",
    "    none_tkn = 'zip3-None' # <--- you need to change this.\n",
    "    tkn_col = [i for i in df_db.columns if 'tkn' in i][0]\n",
    "    idx2tkn = [none_tkn] +sorted(list(set(itertools.chain(*fldtkn_args['external_source'][tkn_col].to_list()))))\n",
    "    print(len(idx2tkn[:10]))\n",
    "\n",
    "else:\n",
    "    assert FldType in FLD_TYPE_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d51e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_record import get_and_save_vocab_from_idx2tkn\n",
    "Vocab = get_and_save_vocab_from_idx2tkn(idx2tkn, **fldtkn_args)\n",
    "Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6eb0",
   "metadata": {},
   "source": [
    "# Save and Load PyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import convert_variables_to_pystirng, load_module_variables\n",
    "\n",
    "prefix = ['import pandas as pd', 'import numpy as np']\n",
    "iterative_variables = [column_to_top_values, item_to_configs, idx2tkn] # <-- don't forget to update this.\n",
    "fn_variables = [tokenizer_fn]\n",
    "pycode = convert_variables_to_pystirng(iterative_variables = iterative_variables, fn_variables = fn_variables, prefix = prefix)\n",
    "RecName = record_args['RecName']\n",
    "pypath = fldtkn_args['pypath']\n",
    "# print(pypath)\n",
    "with open(pypath, 'w') as file: file.write(pycode)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = fldtkn_args['pypath']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_module_variables(pypath)\n",
    "\n",
    "# tokenizer_fn\n",
    "tokenizer_fn = module.MetaDict['tokenizer_fn']\n",
    "\n",
    "# idx2tkn\n",
    "idx2tkn = module.MetaDict['idx2tkn']\n",
    "\n",
    "if 'column_to_top_values' in module.MetaDict:\n",
    "    fldtkn_args['column_to_top_values'] = module.MetaDict['column_to_top_values']\n",
    "if 'item_to_configs' in module.MetaDict:\n",
    "    fldtkn_args['item_to_configs'] = module.MetaDict['item_to_configs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bf04a",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_record import tokenizer_dfHumanRecAttr\n",
    "from datetime import datetime\n",
    "\n",
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args,\n",
    "                                 use_tknidx = True)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args, \n",
    "                                 use_tknidx = False)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
