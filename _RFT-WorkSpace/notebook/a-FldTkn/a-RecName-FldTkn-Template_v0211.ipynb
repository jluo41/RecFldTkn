{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c938bf1",
   "metadata": {},
   "source": [
    "# Space\n",
    "\n",
    "\n",
    "version: 2024-02-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c872edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd \n",
    "from IPython.display import display, HTML\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import PROJECT, TaskName, SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_RFT'], 'config_recfldtkn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aca990",
   "metadata": {},
   "source": [
    "# [Part 1] Load dfHumanRecAttr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817dae8",
   "metadata": {},
   "source": [
    "## [Step 1]** Create FldTknName\n",
    "\n",
    "Motivation: To provide a flexible way to handle different types of configuration files or data records\n",
    "\n",
    "Aim: FldTknName is set to the name of a file ('Food-NutriN2CTkn' in this case); FldType is set to 'N2C' in this case.\n",
    "\n",
    "Input:\n",
    "\n",
    "Output:FldTknName and FldType\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red;\">Instruction:</span>\n",
    "1. change 'P-DemoCateTkn', in this example: P is rec name and DemoCateTkn is a specific tkn name\n",
    "2. change FldType. In general, we have a few different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff3b00-c0db-4944-8fb3-01e95be33c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "FldTknName = 'P-DemoCateTkn' # <-------- select your yaml file name\n",
    "FldType = 'Cate'\n",
    "###########################\n",
    "\n",
    "FLD_TYPE_LIST = ['Cate', 'N2C', 'Nume', 'External']\n",
    "assert FldType in FLD_TYPE_LIST\n",
    "RecName = FldTknName.split('-')[0]\n",
    "print(RecName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e52ea",
   "metadata": {},
   "source": [
    "## [Step 2] Open  Rec yaml file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recfldtkn.configfn import load_cohort_args, load_record_args, load_fldtkn_args\n",
    "\n",
    "# step 1: create the FldTkn yaml file in recfldtkn_config_path\n",
    "cohort_args = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "record_args = load_record_args(RecName, cohort_args)\n",
    "fldtkn_args = load_fldtkn_args(RecName, FldTknName, cohort_args)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = record_args['yaml_file_path']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6de5f",
   "metadata": {},
   "source": [
    "## [Step 3]**: Add FldTknInfo to Record Yaml\n",
    "\n",
    "``` yaml\n",
    "FldTknInfo:\n",
    "  # <---- uodated information >\n",
    "  P-DemoCateTkn:  # RecName-FldTkn \n",
    "    value_cols:   # value columns\n",
    "      - Gender\n",
    "      - DiseaseType\n",
    "      - MRSegmentID\n",
    "  # <--------------------->\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba03a5",
   "metadata": {},
   "source": [
    "## [Step 4] Load FldTkn Args (from Record yaml's FldTkn part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import load_ds_rec_and_info\n",
    "# load fldtkn_args\n",
    "fldtkn_args = load_fldtkn_args(RecName, FldTknName, cohort_args)\n",
    "fldtkn_args['attr_cols']\n",
    "\n",
    "# load dfHumanRecAttr\n",
    "value_cols = fldtkn_args['value_cols']\n",
    "attr_cols  = fldtkn_args['attr_cols'] # record_args['RecIDChain'] + value_cols\n",
    "\n",
    "print(value_cols)\n",
    "print(attr_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9c83b",
   "metadata": {},
   "source": [
    "## [Step 5] Prepare dfHumanRecAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be11acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "cohort_label_list = [1]\n",
    "############################\n",
    "\n",
    "\n",
    "dsHumanRecAttr, _ = load_ds_rec_and_info(RecName, cohort_args, cohort_label_list)\n",
    "dfHumanRecAttr = dsHumanRecAttr.select_columns(attr_cols).to_pandas()\n",
    "print(dfHumanRecAttr.shape)\n",
    "\n",
    "\n",
    "if len(dfHumanRecAttr) > 100000:\n",
    "    dfHumanRecAttr = dfHumanRecAttr.head(100000)\n",
    "    \n",
    "dfHumanRecAttr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5907a",
   "metadata": {},
   "source": [
    "# [Part 2]: Design $\\phi$ pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06bac8",
   "metadata": {},
   "source": [
    "## [Step 1]* [Pre-defined Token Vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fldtkn_args['attr_cols'])\n",
    "print(fldtkn_args['value_cols'])\n",
    "print('FldType:', FldType)\n",
    "\n",
    "column_to_top_values = {}\n",
    "item_to_configs = {}\n",
    "\n",
    "if FldType == 'Cate':\n",
    "    ############################### for Cate Tkn only\n",
    "    column_to_top_values = {}\n",
    "    TOP_NUM = 30\n",
    "    cols = fldtkn_args['value_cols']\n",
    "    for col in cols:\n",
    "        top_tkn = list(dfHumanRecAttr[col].value_counts().iloc[:TOP_NUM].index)\n",
    "        print(col, len(top_tkn), top_tkn)\n",
    "        column_to_top_values[col] = top_tkn # tolist()\n",
    "    ###############################\n",
    "        \n",
    "elif FldType == 'N2C':\n",
    "    ############################### for N2C Tkn only, you need to modify this part. \n",
    "    cols = fldtkn_args['value_cols']\n",
    "    descp = dfHumanRecAttr[cols].astype(float).describe().round(2)#.to_dict()\n",
    "    print(descp)\n",
    "    item_to_configs = {\n",
    "       #  'XXX': {'Max': 600, 'Min': 1, 'INTERVAL': 1}, # <--- you need to modify this part\n",
    "    }\n",
    "    ###############################\n",
    "\n",
    "elif FldType == 'External':\n",
    "    df_db = fldtkn_args['external_source']\n",
    "    display(HTML(df_db.head().to_html()))\n",
    "\n",
    "else:\n",
    "    assert FldType in FLD_TYPE_LIST\n",
    "    \n",
    "fldtkn_args[f'column_to_top_values'] = column_to_top_values\n",
    "fldtkn_args['item_to_configs'] = item_to_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72185e19",
   "metadata": {},
   "source": [
    "## [Step 2]* Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9849ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "################################## You might need to change it a bit. \n",
    "def tokenizer_fn(rec, fldtkn_args):\n",
    "    d = {}\n",
    "\n",
    "    # #----------- Cate\n",
    "    column_to_top_values = fldtkn_args[f'column_to_top_values']\n",
    "    for key in column_to_top_values:\n",
    "        top_values = column_to_top_values[key]\n",
    "        value = rec.get(key, 'unk')\n",
    "        if value not in top_values and value != 'unk': value = 'minor'\n",
    "        key_value = f\"{key}_{value}\"  # Concatenate key and value\n",
    "        d[key_value] = 1\n",
    "\n",
    "    # #------------ N2C with interval and intervel level. \n",
    "    # item_to_configs = fldtkn_args['item_to_configs']\n",
    "    # for item, configs in item_to_configs.items():\n",
    "    #     Max = configs['Max']\n",
    "    #     Min = configs['Min']\n",
    "    #     INTERVAL = configs['INTERVAL']\n",
    "    #     if pd.isnull(rec.get(item, None)):\n",
    "    #         d[f\"{item}:None\"] = 1\n",
    "    #     elif float(rec[item]) > Max:\n",
    "    #         d[ f\"{item}:Above{Max}\"] = 1\n",
    "    #     elif float(rec[item]) < Min:\n",
    "    #         d[ f\"{item}:Below{Min}\"] = 1\n",
    "    #     else:\n",
    "    #         lower_bound = int((float(rec[item]) // INTERVAL) * INTERVAL)\n",
    "    #         upper_bound = int(lower_bound + INTERVAL)\n",
    "    #         # Calculate the proportion of value within the interval\n",
    "    #         proportion = (float(rec[item]) - lower_bound) / INTERVAL\n",
    "    #         # Construct the keys\n",
    "    #         key1 = f\"{item}:{lower_bound}~{upper_bound}\"\n",
    "    #         key2 = f\"{key1}Level\"\n",
    "    #         # Add them to the dictionary with appropriate weights\n",
    "    #         d[key1] = 1\n",
    "    #         d[key2] = proportion\n",
    "\n",
    "    # #------------ Nume\n",
    "    # for col in fldtkn_args['value_cols']:\n",
    "    #     x = rec[col]\n",
    "    #     if pd.isnull(x):\n",
    "    #         d[f'{col}_None'] = 1\n",
    "    #     else:\n",
    "    #         d[col] = float(x)\n",
    "\n",
    "    # #------------ ExternalSource: zip3 as an example. This is case by case. \n",
    "    ##############################################################\n",
    "    ##     this part can be moved to big Phi in the future.     ##\n",
    "    ##############################################################\n",
    "    # df_db = fldtkn_args['external_source']\n",
    "    # try:\n",
    "    #     external_id = str(int(rec['patient_zipcode_3']))\n",
    "    # except:\n",
    "    #     external_id = str(rec['patient_zipcode_3'])\n",
    "\n",
    "    # if external_id not in df_db['Zip3'].to_list():\n",
    "    #     return {'tkn': ['zip3-None'], 'wgt':[1]}\n",
    "    # row = df_db[df_db['Zip3'] == external_id].iloc[0].to_dict()\n",
    "    # tkn_col = [i for i in df_db.columns if 'tkn' in i][0]\n",
    "    # wgt_col = [i for i in df_db.columns if 'wgt' in i][0]\n",
    "    # d = dict(zip(row[tkn_col], row[wgt_col]))\n",
    "\n",
    "\n",
    "    tkn = list(d.keys())\n",
    "    wgt = list(d.values())\n",
    "    output = {'tkn': tkn, 'wgt': wgt}\n",
    "    return output\n",
    "##################################\n",
    "\n",
    "tokenizer_fn.fn_string = inspect.getsource(tokenizer_fn)\n",
    "\n",
    "print('show tokenizer_fn result')\n",
    "rec = dfHumanRecAttr.iloc[0]\n",
    "print(rec.to_dict())\n",
    "print(tokenizer_fn(rec, fldtkn_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709344e5",
   "metadata": {},
   "source": [
    "## [Step 3]* Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def sort_fn(s):\n",
    "    try:\n",
    "        return int(s.split(':')[-1].split('~')[0])\n",
    "    except:\n",
    "        return float('inf')\n",
    "    \n",
    "print('show idx2tkn for FldType:', FldType )\n",
    "if FldType == 'Cate':\n",
    "    ############################################## Cate Tkn only\n",
    "    idx2tkn = []\n",
    "    for col, values in column_to_top_values.items():\n",
    "        idx2tkn = idx2tkn + [f'{col}_unk', f'{col}_minor']\n",
    "        for val in values:\n",
    "            idx2tkn.append(f\"{col}_{val}\")\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'N2C':\n",
    "    ############################################## for N2C only\n",
    "    Min, Max = -10, 3000 # <---- keep this as default. don't change it.\n",
    "    df_simu = pd.DataFrame({\n",
    "        col: [None] + list(range(Min, Max )) for col in item_to_configs.keys()\n",
    "    })\n",
    "    df_sim = pd.DataFrame(df_simu.apply(lambda rec: tokenizer_fn(rec, fldtkn_args), axis = 1).to_list())\n",
    "    idx2tkn = sorted(list(set(itertools.chain(*df_sim['tkn'].to_list()))))\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'Nume':\n",
    "    ############################################## for Nume\n",
    "    idx2tkn = fldtkn_args['value_cols'] + [f'{col}_None' for col in fldtkn_args['value_cols']]\n",
    "    print(len(idx2tkn))\n",
    "    print(idx2tkn[:10])\n",
    "    ##############################################\n",
    "\n",
    "elif FldType == 'External':\n",
    "    none_tkn = 'zip3-None' # <--- you need to change this.\n",
    "    tkn_col = [i for i in df_db.columns if 'tkn' in i][0]\n",
    "    idx2tkn = [none_tkn] +sorted(list(set(itertools.chain(*fldtkn_args['external_source'][tkn_col].to_list()))))\n",
    "    print(len(idx2tkn[:10]))\n",
    "\n",
    "else:\n",
    "    assert FldType in FLD_TYPE_LIST\n",
    "\n",
    "\n",
    "idx2tkn = sorted(idx2tkn, key = sort_fn)\n",
    "idx2tkn = ['unk'] + idx2tkn\n",
    "print(len(idx2tkn))\n",
    "idx2tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d51e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_record import get_and_save_vocab_from_idx2tkn\n",
    "Vocab = get_and_save_vocab_from_idx2tkn(idx2tkn, **fldtkn_args)\n",
    "Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6eb0",
   "metadata": {},
   "source": [
    "# Part 4: Application\n",
    "\n",
    "## [Step 1] Save PyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import convert_variables_to_pystirng, load_module_variables\n",
    "\n",
    "prefix = ['import pandas as pd', 'import numpy as np']\n",
    "iterative_variables = [column_to_top_values, item_to_configs, idx2tkn] # <-- don't forget to update this.\n",
    "fn_variables = [tokenizer_fn]\n",
    "pycode = convert_variables_to_pystirng(iterative_variables = iterative_variables, fn_variables = fn_variables, prefix = prefix)\n",
    "RecName = record_args['RecName']\n",
    "pypath = fldtkn_args['pypath']\n",
    "# print(pypath)\n",
    "with open(pypath, 'w') as file: file.write(pycode)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = fldtkn_args['pypath']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cabf8d",
   "metadata": {},
   "source": [
    "\n",
    "## [Step 2] Load PyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_module_variables(pypath)\n",
    "\n",
    "# tokenizer_fn\n",
    "tokenizer_fn = module.MetaDict['tokenizer_fn']\n",
    "\n",
    "# idx2tkn\n",
    "idx2tkn = module.MetaDict['idx2tkn']\n",
    "\n",
    "if 'column_to_top_values' in module.MetaDict:\n",
    "    fldtkn_args['column_to_top_values'] = module.MetaDict['column_to_top_values']\n",
    "if 'item_to_configs' in module.MetaDict:\n",
    "    fldtkn_args['item_to_configs'] = module.MetaDict['item_to_configs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bf04a",
   "metadata": {},
   "source": [
    "## [Step 3] Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_record import tokenizer_dfHumanRecAttr\n",
    "from datetime import datetime\n",
    "\n",
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args,\n",
    "                                 use_tknidx = True)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args, \n",
    "                                 use_tknidx = False)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
