{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab3f242",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80023bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from IPython.display import display, HTML\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "\n",
    "import sys\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "from proj_space import PROJECT, TaskName, SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aaed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.configfn import load_cohort_args\n",
    "\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_FN'], 'config_recfldtkn/')\n",
    "cohort_args = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "\n",
    "RawRootID = cohort_args['RawRootID']\n",
    "RootID = cohort_args['RootID']\n",
    "RootIDLength = cohort_args['RootIDLength']\n",
    "print(RawRootID, RootID, RootIDLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.configfn import get_rec_related_size\n",
    "\n",
    "P2RecNumName = cohort_args['RecName']\n",
    "RFT_GROUP_SIZE, idx_group_size, usebucket = get_rec_related_size(P2RecNumName, cohort_args)\n",
    "print(RFT_GROUP_SIZE, idx_group_size, usebucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6322cf4-8fe3-4235-bb43-3f5a5b04ff20",
   "metadata": {},
   "source": [
    "# Cohort: Pick A Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "my_parser = argparse.ArgumentParser(description='Process Input.')\n",
    "\n",
    "\n",
    "# Add the arguments\n",
    "my_parser.add_argument('--cohort_name',\n",
    "                    metavar='cohort_name',\n",
    "                    default = None, \n",
    "                    type=str,\n",
    "                    help='the cohort_name to process')\n",
    "\n",
    "my_parser.add_argument('--cohort_label',\n",
    "                    metavar='cohort_label',\n",
    "                    default = None, \n",
    "                    type=str,\n",
    "                    help='the label for cohort_name to process')\n",
    "\n",
    "my_parser.add_argument('--list_cohort_name',\n",
    "                    metavar='list_cohort_name',\n",
    "                    type=str,\n",
    "                    help='the groupname_ids to process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### in notebook ###################\n",
    "args_information = [\n",
    "    '--cohort_label', '1',\n",
    "    '--list_cohort_name', 'false'\n",
    "]\n",
    "\n",
    "args = my_parser.parse_args(args_information)\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95f1c3-2ef7-4558-8f99-69d671fea6bb",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15682643-3d17-42bb-960e-37cc72df08fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "######################### You many want to change these functions to make it run.\n",
    "selected_source_file_suffix_list = ['csv']\n",
    "excluded_cols = []\n",
    "\n",
    "def get_id_column(columns):\n",
    "    if 'patient_id_encoded' in columns: id_column = 'patient_id_encoded' \n",
    "    return id_column\n",
    "\n",
    "def get_tablename_from_file(file_path):\n",
    "    name = file_path.split('/')[-1].split('_df_')[0]\n",
    "    return name\n",
    "\n",
    "def read_column_value_counts_by_chunk(RawRootID, chunk_size, file_path, rawdf = None):\n",
    "    if type(rawdf) != pd.DataFrame:\n",
    "        columns = pd.read_csv(file_path, nrows=0).columns\n",
    "    else:\n",
    "        columns = rawdf.columns \n",
    "    id_column = get_id_column(columns)\n",
    "\n",
    "    if type(rawdf) == pd.DataFrame:\n",
    "        result = rawdf[id_column].value_counts()\n",
    "    else:\n",
    "        li = [chunk[id_column].value_counts() for chunk in pd.read_csv(file_path, \n",
    "                                                                       usecols = [id_column], \n",
    "                                                                       chunksize=chunk_size, \n",
    "                                                                       low_memory=False)]\n",
    "        result = pd.concat(li)\n",
    "        result = result.groupby(result.index).sum()\n",
    "\n",
    "    name = get_tablename_from_file(file_path)\n",
    "    result = result.reset_index().rename(columns = {'count': 'RecNum', id_column: RawRootID})\n",
    "    result['RecName'] = name\n",
    "    return result\n",
    "#########################\n",
    "\n",
    "\n",
    "get_id_column.fn_string = inspect.getsource(get_id_column)\n",
    "get_tablename_from_file.fn_string = inspect.getsource(get_tablename_from_file)\n",
    "read_column_value_counts_by_chunk.fn_string = inspect.getsource(read_column_value_counts_by_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import convert_variables_to_pystirng, load_module_variables\n",
    "\n",
    "prefix = ['import pandas as pd', 'import numpy as np']\n",
    "iterative_variables = [selected_source_file_suffix_list, excluded_cols]\n",
    "fn_variables = [get_id_column, get_tablename_from_file, read_column_value_counts_by_chunk]\n",
    "pycode = convert_variables_to_pystirng(iterative_variables = iterative_variables, \n",
    "                                       fn_variables = fn_variables, \n",
    "                                       prefix = prefix)\n",
    "pypath = cohort_args['pypath']\n",
    "# print(pypath)\n",
    "with open(pypath, 'w') as file: file.write(pycode)\n",
    "# Create a HTML link and display it\n",
    "full_path = os.path.join(WORKSPACE_PATH, pypath)\n",
    "display(HTML(f'{pypath} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262266b9",
   "metadata": {},
   "source": [
    "# Process dfHumanRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d56e64-c0a6-4f4a-845f-a601e377727f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from recfldtkn.pipeline_record import get_cohort_level_record_number_counts\n",
    "\n",
    "def get_cohort_level_record_number_counts(cohort_name, cohort_label, cohort_args, filepath_to_rawdf = None):\n",
    "    ###############################\n",
    "    pypath = cohort_args['pypath']\n",
    "    module = load_module_variables(pypath)\n",
    "    get_id_column = module.get_id_column\n",
    "    read_column_value_counts_by_chunk = module.read_column_value_counts_by_chunk\n",
    "    excluded_cols = module.excluded_cols\n",
    "    pid_recnum_result_fn = read_column_value_counts_by_chunk\n",
    "    selected_source_file_suffix_list = module.selected_source_file_suffix_list\n",
    "    ###############################\n",
    "\n",
    "    RawRootID = cohort_args['RawRootID']\n",
    "    RootID = cohort_args['RootID']  \n",
    "    RootIDLength = cohort_args['RootIDLength']\n",
    "    cohort_config = cohort_args['CohortInfo'][cohort_name]\n",
    "    FolderPath = cohort_config['FolderPath']\n",
    "    chunk_size = 100000\n",
    "    \n",
    "    logger.info(f'=======cohort_label-{cohort_label}: cohort_name-{cohort_name}=======')\n",
    "    logger.info(cohort_config)\n",
    "    \n",
    "    if filepath_to_rawdf is None: \n",
    "        file_list = [i for i in os.listdir(FolderPath) if i.split('.')[-1] in selected_source_file_suffix_list]\n",
    "        fullfile_list = [os.path.join(FolderPath, i) for i in file_list]\n",
    "        logger.info(f'{FolderPath} <-- FolderPath')\n",
    "        logger.info(f'{len(fullfile_list)} <--- fullfile_list')\n",
    "        filepath_to_rawdf = {filepath: None for filepath in fullfile_list}\n",
    "\n",
    "    L = []\n",
    "    for file_path, rawdf in filepath_to_rawdf.items():\n",
    "        if type(rawdf) == pd.DataFrame:\n",
    "            if len(rawdf) == 0: continue\n",
    "            result = pid_recnum_result_fn(RawRootID, chunk_size, file_path, rawdf)\n",
    "            logger.info(f\"'{file_path}' # {result.shape}\")\n",
    "        elif file_path.split('.')[-1] == 'csv':\n",
    "            if os.stat(file_path).st_size == 0: \n",
    "                logger.info(f\"'{file_path}' # emtpy file\"); continue\n",
    "            try:\n",
    "                result = pid_recnum_result_fn(RawRootID, chunk_size, file_path, rawdf)\n",
    "                logger.info(f\"'{file_path}' # {result.shape}\")\n",
    "            except:\n",
    "                logger.info(f\"'{file_path}' # error file\"); continue\n",
    "        else:\n",
    "            if file_path.split('.')[-1] == 'parquet':\n",
    "                rawdf = pd.read_parquet(file_path)\n",
    "            elif file_path.split('.')[-1] == 'p':\n",
    "                rawdf = pd.read_pickle(file_path)\n",
    "            else:\n",
    "                raise ValueError(f'file type not supported: {file_path}')\n",
    "            result = pid_recnum_result_fn(RawRootID, chunk_size, file_path, rawdf)\n",
    "            logger.info(f\"'{file_path}' # {result.shape}\")\n",
    "            \n",
    "        L.append(result)\n",
    "    logger.info(f'{len(L)} <---- types of dfRec so far')\n",
    "    df_all = pd.concat(L, ignore_index=True)\n",
    "    df_pivot = df_all.pivot(index=RawRootID, columns='RecName', values='RecNum').reset_index()\n",
    "\n",
    "    recname_cols = [i for i in df_pivot.columns if i != RawRootID]\n",
    "    included_cols = [i for i in recname_cols if i not in excluded_cols]\n",
    "    rec_count = df_pivot[included_cols].sum(axis = 1)\n",
    "    \n",
    "    df_Human = df_pivot[rec_count > 0].reset_index(drop = True)\n",
    "    df_Human['TotalRecNum'] = df_Human[included_cols].sum(axis = 1)\n",
    "    logger.info(len(df_Human))\n",
    "\n",
    "    CohortLabel = cohort_config['cohort_label']\n",
    "    df_Human[RootID] = range(1, len(df_Human) + 1)\n",
    "    df_Human[RootID] = df_Human[RootID].apply(lambda x: int(str(CohortLabel) + str(x).zfill(RootIDLength)))\n",
    "    df_Human['CohortLabel'] = CohortLabel\n",
    "    cols = ['PID'] + [i for i in df_Human.columns if i not in ['PID']]\n",
    "    df_Human = df_Human[cols].reset_index(drop = True)\n",
    "\n",
    "    return df_Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_label = int(args.cohort_label)\n",
    "cohort_name = [v for k, v in cohort_args['CohortInfo'].items() \n",
    "               if v['cohort_label'] == cohort_label][0]['cohort_name']\n",
    "\n",
    "print(f'=============== {cohort_name}: {cohort_label} ======================')\n",
    "print(cohort_name, cohort_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21432602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Human = get_cohort_level_record_number_counts(cohort_name, cohort_label, cohort_args)\n",
    "df_Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "ds_HumanRec = datasets.Dataset.from_pandas(df_Human)\n",
    "print(ds_HumanRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b947e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_args['RecName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SPACE['DATA_RFT'])\n",
    "\n",
    "full_cohort_name = f'{cohort_label}-{cohort_name}'\n",
    "print(full_cohort_name)\n",
    "# ------------------------------------------------------------------------- # \n",
    "path = os.path.join(SPACE['DATA_RFT'], full_cohort_name, cohort_args['RecName'] + '_data')\n",
    "print(path)\n",
    "ds_HumanRec.save_to_disk(path)\n",
    "print(ds_HumanRec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711585b7",
   "metadata": {},
   "source": [
    "# Select Patients with PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from recfldtkn.loadtools import load_ds_rec_and_info\n",
    "\n",
    "def load_ds_rec_and_info(record_name, cohort_args, cohort_label_list = None):\n",
    "    SPACE = cohort_args['SPACE']\n",
    "    cohort_list = [i for i in os.listdir(SPACE['DATA_RFT'])]\n",
    "    if cohort_label_list is not None:\n",
    "        cohort_label_list = [str(i) for i in cohort_label_list]\n",
    "        cohort_list = [i for i in cohort_list if i.split('-')[0] in cohort_label_list]\n",
    "    l = []\n",
    "    linfo = []\n",
    "    print(cohort_list)\n",
    "    for cohort_full_name in cohort_list:\n",
    "        data_folder = os.path.join(SPACE['DATA_RFT'], cohort_full_name, record_name + '_data')\n",
    "        # logger.info(f'Load from disk: {data_folder} ...')\n",
    "        ds_rec = datasets.Dataset.load_from_disk(data_folder)\n",
    "        l.append(ds_rec)\n",
    "        info_folder = os.path.join(SPACE['DATA_RFT'], cohort_full_name, record_name + '_info')\n",
    "        if os.path.exists(info_folder):\n",
    "            ds_rec_info = datasets.Dataset.load_from_disk(info_folder)\n",
    "            linfo.append(ds_rec_info)\n",
    "    ds_rec = datasets.concatenate_datasets(l)\n",
    "    if len(linfo) == 0:\n",
    "        ds_rec_info = None\n",
    "    else:\n",
    "        ds_rec_info = datasets.concatenate_datasets(linfo)\n",
    "    return ds_rec, ds_rec_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515dbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(SPACE['DATA_RFT'], cohort_args['RecName'], cohort_name)\n",
    "# print(path)\n",
    "# ds_HumanRec = datasets.load_from_disk(path)\n",
    "# print(ds_HumanRec)\n",
    "# df_Human = ds_HumanRec.to_pandas()\n",
    "# df_Human.head()\n",
    "\n",
    "ds_Human, _ = load_ds_rec_and_info(cohort_args['RecName'], cohort_args)\n",
    "df_Human = ds_Human.to_pandas()\n",
    "df_Human\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a45c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "RootID = cohort_args['RootID']\n",
    "RawRootID = cohort_args['RawRootID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_list = [1013405, 1002538, 1022279, 1004432, 1016032, 1032308, 1031363, 1001133, 1007343, 1026067]\n",
    "print(PID_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_records_Ri(RawRootID_sample, RawRootID, cohort_args):\n",
    "    \n",
    "    d = {}\n",
    "    cohort_config = cohort_args['CohortInfo'][cohort_name]\n",
    "    FolderPath = cohort_config['FolderPath']\n",
    "    chunk_size = 100000\n",
    "\n",
    "    file_list = sorted(os.listdir(FolderPath))\n",
    "    file_list = [i for i in file_list if 'csv' in i]\n",
    "    for file in file_list:\n",
    "        full_file = os.path.join(FolderPath, file)\n",
    "        li = [chunk[chunk[RawRootID] == RawRootID_sample] \n",
    "              for chunk in pd.read_csv(full_file, chunksize=chunk_size, low_memory=False)]\n",
    "        result = pd.concat(li)\n",
    "        logger.info(f'{result.shape}: {file}')\n",
    "        if len(result) == 0: continue\n",
    "        d[file] = result\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for PID_sample in PID_list:\n",
    "    print('\\n======== PID_sample:', PID_sample, '========')\n",
    "    PIDInfo_dict = df_Human[df_Human[RootID] == PID_sample].iloc[0].to_dict()\n",
    "    RawRootID_sample = PIDInfo_dict[RawRootID]\n",
    "    d = get_patient_records_Ri(RawRootID_sample, RawRootID, cohort_args)\n",
    "    folder = os.path.join(SPACE['DATA_RAW'], 'patient_sample', str(PID_sample))\n",
    "    if os.path.exists(folder) == False: os.makedirs(folder)\n",
    "    for file, df in d.items():\n",
    "        df.to_csv(os.path.join(folder, file), index = False)\n",
    "        print(file, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263aa064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
