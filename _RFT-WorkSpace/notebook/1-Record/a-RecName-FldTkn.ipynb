{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c938bf1",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c872edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd \n",
    "from IPython.display import display, HTML\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "sys.path.append(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import PROJECT, TaskName, SPACE\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "recfldtkn_config_path = os.path.join(SPACE['CODE_RFT'], 'config_recfldtkn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817dae8",
   "metadata": {},
   "source": [
    "# Load dfHumanRecAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff3b00-c0db-4944-8fb3-01e95be33c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "FldTknName = 'RecName-FldTkn'# <-------- select your yaml file name\n",
    "###########################\n",
    "\n",
    "RecName = FldTknName.split('-')[0]\n",
    "print(RecName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recfldtkn.configfn import load_cohort_args, load_record_args, load_fldtkn_args\n",
    "\n",
    "# step 1: create the FldTkn yaml file in recfldtkn_config_path\n",
    "cohort_args = load_cohort_args(recfldtkn_config_path, SPACE)\n",
    "record_args = load_record_args(RecName, cohort_args)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = record_args['yaml_file_path']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import load_ds_rec_and_info\n",
    "# load fldtkn_args\n",
    "fldtkn_args = load_fldtkn_args(RecName, FldTknName, cohort_args)\n",
    "\n",
    "# load dfHumanRecAttr\n",
    "value_cols = fldtkn_args['value_cols']\n",
    "attr_cols  = fldtkn_args['attr_cols'] # record_args['RecIDChain'] + value_cols\n",
    "dsHumanRecAttr, _ = load_ds_rec_and_info(RecName, cohort_args)\n",
    "dfHumanRecAttr = dsHumanRecAttr.select_columns(attr_cols).to_pandas()\n",
    "print(dfHumanRecAttr.shape)\n",
    "dfHumanRecAttr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06bac8",
   "metadata": {},
   "source": [
    "# [Pre-defined Token Vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fldtkn_args['attr_cols'])\n",
    "\n",
    "############################### for Cate Tkn only\n",
    "column_to_top_values = {}\n",
    "# TOP_NUM = 30\n",
    "# cols = fldtkn_args['value_cols']\n",
    "# for col in cols:\n",
    "#     top_tkn = list(dfHumanRecAttr[col].value_counts().iloc[:TOP_NUM].index)\n",
    "#     print(col, len(top_tkn), top_tkn)\n",
    "#     column_to_top_values[col] = top_tkn # tolist()\n",
    "fldtkn_args[f'column_to_top_values'] = column_to_top_values\n",
    "###############################\n",
    "\n",
    "\n",
    "# ##################### N2C only\n",
    "item_to_configs = {} # for N2C only, if not N2C, you can leave it empty.\n",
    "# print(fldtkn_args['value_cols'])\n",
    "# cols = fldtkn_args['value_cols']\n",
    "# descp = dfHumanRecAttr[cols].astype(float).describe().round(2)#.to_dict()\n",
    "# print(descp)\n",
    "# item_to_configs = {\n",
    "#     'XXX': {'Max': 600, 'Min': 1, 'INTERVAL': 1},\n",
    "# }\n",
    "fldtkn_args['item_to_configs'] = item_to_configs\n",
    "# #####################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72185e19",
   "metadata": {},
   "source": [
    "# [Tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9849ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "################################## You might need to change it a bit. \n",
    "def tokenizer_fn(rec, fldtkn_args):\n",
    "    column_to_top_values = fldtkn_args[f'column_to_top_values']\n",
    "    \n",
    "    d = {}\n",
    "    for key in column_to_top_values:\n",
    "        top_values = column_to_top_values[key]\n",
    "        value = rec.get(key, 'unk')\n",
    "        if value not in top_values and value != 'unk': value = 'minor'\n",
    "        key_value = f\"{key}_{value}\"  # Concatenate key and value\n",
    "        d[key_value] = 1\n",
    "\n",
    "    tkn = list(d.keys())\n",
    "    wgt = list(d.values())\n",
    "    output = {'tkn': tkn, 'wgt': wgt}\n",
    "    return output\n",
    "##################################\n",
    "\n",
    "tokenizer_fn.fn_string = inspect.getsource(tokenizer_fn)\n",
    "\n",
    "print('show tokenizer_fn result')\n",
    "rec = dfHumanRecAttr.iloc[0]\n",
    "print(rec.to_dict())\n",
    "print(tokenizer_fn(rec, fldtkn_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709344e5",
   "metadata": {},
   "source": [
    "# [Vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## Cate Tkn only\n",
    "# idx2tkn = []\n",
    "# for col, values in column_to_top_values.items():\n",
    "#     idx2tkn = idx2tkn + [f'{col}_unk', f'{col}_minor']\n",
    "#     for val in values:\n",
    "#         idx2tkn.append(f\"{col}_{val}\")\n",
    "# print(len(idx2tkn))\n",
    "# print(idx2tkn[:10])\n",
    "##############################################\n",
    "\n",
    "############################################## for N2C only\n",
    "# import itertools\n",
    "# Min, Max = -10, 3000 # <---- keep this as default. don't change it.\n",
    "# df_simu = pd.DataFrame({\n",
    "#     col: [None] + list(range(Min, Max )) for col in item_to_configs.keys()\n",
    "# })\n",
    "# df_sim = pd.DataFrame(df_simu.apply(lambda rec: tokenizer_fn(rec, fldtkn_args), axis = 1).to_list())\n",
    "# idx2tkn = sorted(list(set(itertools.chain(*df_sim['tkn'].to_list()))))\n",
    "# print(len(idx2tkn))\n",
    "# print(idx2tkn[:10])\n",
    "##############################################\n",
    "\n",
    "############################################## for Nume\n",
    "# idx2tkn = fldtkn_args['value_cols'] + [f'{col}_None' for col in fldtkn_args['value_cols']]\n",
    "# print(len(idx2tkn))\n",
    "# print(idx2tkn[:10])\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d51e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_record import get_and_save_vocab_from_idx2tkn\n",
    "Vocab = get_and_save_vocab_from_idx2tkn(idx2tkn, **fldtkn_args)\n",
    "Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6eb0",
   "metadata": {},
   "source": [
    "# Save and Load PyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.loadtools import convert_variables_to_pystirng, load_module_variables\n",
    "\n",
    "prefix = ['import pandas as pd', 'import numpy as np']\n",
    "iterative_variables = [ column_to_top_values, idx2tkn ]\n",
    "fn_variables = [tokenizer_fn]\n",
    "pycode = convert_variables_to_pystirng(iterative_variables = iterative_variables, fn_variables = fn_variables, prefix = prefix)\n",
    "RecName = record_args['RecName']\n",
    "pypath = fldtkn_args['pypath']\n",
    "# print(pypath)\n",
    "with open(pypath, 'w') as file: file.write(pycode)\n",
    "\n",
    "# Create a HTML link and display it\n",
    "path = fldtkn_args['pypath']\n",
    "full_path = os.path.join(WORKSPACE_PATH, path)\n",
    "display(HTML(f'{path} <a href=\"{full_path}\" target=\"_blank\">Open File</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_module_variables(pypath)\n",
    "\n",
    "# tokenizer_fn\n",
    "tokenizer_fn = module.MetaDict['tokenizer_fn']\n",
    "\n",
    "# idx2tkn\n",
    "idx2tkn = module.MetaDict['idx2tkn']\n",
    "\n",
    "if 'column_to_top_values' in module.MetaDict:\n",
    "    fldtkn_args['column_to_top_values'] = module.MetaDict['column_to_top_values']\n",
    "if 'item_to_configs' in module.MetaDict:\n",
    "    fldtkn_args['item_to_configs'] = module.MetaDict['item_to_configs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bf04a",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.pipeline_record import tokenizer_dfHumanRecAttr\n",
    "from datetime import datetime\n",
    "\n",
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args,\n",
    "                                 use_tknidx = True)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('s', datetime.now())\n",
    "RootID, RecID = cohort_args['RootID'], record_args['RecID']\n",
    "df_fld = tokenizer_dfHumanRecAttr(dfHumanRecAttr, RootID, RecID, FldTknName, \n",
    "                                 tokenizer_fn, Vocab, fldtkn_args, \n",
    "                                 use_tknidx = False)\n",
    "print('e', datetime.now())\n",
    "total_memory = df_fld.memory_usage(index=True).sum()\n",
    "print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "df_fld.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
